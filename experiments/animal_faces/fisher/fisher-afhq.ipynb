{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1176357,"sourceType":"datasetVersion","datasetId":667852},{"sourceId":181928,"sourceType":"modelInstanceVersion","modelInstanceId":155068,"modelId":177544}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !git clone https://github.com/Jsrsky/machine_unlearning_experiments\n# %cd machine_unlearning_experiments/experiments/animal_faces/fisher","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:06.002607Z","iopub.execute_input":"2025-04-03T17:00:06.002839Z","iopub.status.idle":"2025-04-03T17:00:29.744270Z","shell.execute_reply.started":"2025-04-03T17:00:06.002805Z","shell.execute_reply":"2025-04-03T17:00:29.743258Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'machine_unlearning_experiments'...\nremote: Enumerating objects: 465, done.\u001b[K\nremote: Counting objects: 100% (91/91), done.\u001b[K\nremote: Compressing objects: 100% (80/80), done.\u001b[K\nremote: Total 465 (delta 14), reused 34 (delta 9), pack-reused 374 (from 3)\u001b[K\nReceiving objects: 100% (465/465), 628.99 MiB | 37.90 MiB/s, done.\nResolving deltas: 100% (149/149), done.\nUpdating files: 100% (69/69), done.\n/kaggle/working/machine_unlearning_experiments/experiments/animal_faces/fisher\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Dependecies","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport sys\nimport copy\nfrom torchvision import datasets\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:29.746483Z","iopub.execute_input":"2025-04-03T17:00:29.746785Z","iopub.status.idle":"2025-04-03T17:00:38.186164Z","shell.execute_reply.started":"2025-04-03T17:00:29.746750Z","shell.execute_reply":"2025-04-03T17:00:38.185170Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Utils ","metadata":{}},{"cell_type":"code","source":"project_root = Path.cwd().resolve().parents[2]\nif str(project_root) not in sys.path:\n    sys.path.append(str(project_root))\n    \ndata_root = project_root / 'data'\ndata_root.mkdir(parents=True, exist_ok=True)\n\nfrom notebook_setup import setup_notebook\nsetup_notebook()","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:38.187335Z","iopub.execute_input":"2025-04-03T17:00:38.187714Z","iopub.status.idle":"2025-04-03T17:00:38.195265Z","shell.execute_reply.started":"2025-04-03T17:00:38.187685Z","shell.execute_reply":"2025-04-03T17:00:38.194366Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Notebook setup completed. Project root added to sys.path: /kaggle/working/machine_unlearning_experiments\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Device configuration\nfrom utils.utils import DEVICE\n\nprint(f\"Device used: {DEVICE}\")\n\n# Set random seed for reproducibility\nfrom utils.utils import set_seed\nset_seed()\n\nfrom utils.utils import save_model\n\nfrom models.effnetb0 import load_model_effnetb0, init_model_effnetb0\n\n# Merics \nfrom utils.train_test_metrics import test_model, show_metrics\n\n# Recreate Dataloaders from json files\nfrom methods.naive.naive_utils import recreate_dataloaders\n\n# Fisher Information Matrix (FIM) calc and unlearning with FIM\nfrom methods.fisher.fisher_utils import iterative_fisher_unlearn, create_unlearning_dataloader","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:38.196528Z","iopub.execute_input":"2025-04-03T17:00:38.197117Z","iopub.status.idle":"2025-04-03T17:00:39.530355Z","shell.execute_reply.started":"2025-04-03T17:00:38.197089Z","shell.execute_reply":"2025-04-03T17:00:39.529598Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device used: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Parameters (arbitrary chosen)","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 256\nMINI_BATCH_SIZE = 4096\n\nSIGMA = 1\n\nEPS = 1e-6\nMAX_NORM = 0","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:39.531472Z","iopub.execute_input":"2025-04-03T17:00:39.532006Z","iopub.status.idle":"2025-04-03T17:00:39.536144Z","shell.execute_reply.started":"2025-04-03T17:00:39.531963Z","shell.execute_reply":"2025-04-03T17:00:39.535224Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# CALL FISHER","metadata":{}},{"cell_type":"markdown","source":"### Files","metadata":{}},{"cell_type":"code","source":"model_file = project_root / 'experiments/animal_faces/naive/EffNetB0_AFHQ_model.pth'\nsamples_to_unlearn_file = project_root / 'experiments/animal_faces/naive/afhq_samples_to_unlearn_30per.json'\nremaining_dataset_file = project_root / 'experiments/animal_faces/naive/updated_afhq_data_splits.json'","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:39.537378Z","iopub.execute_input":"2025-04-03T17:00:39.537969Z","iopub.status.idle":"2025-04-03T17:00:39.551950Z","shell.execute_reply.started":"2025-04-03T17:00:39.537926Z","shell.execute_reply":"2025-04-03T17:00:39.551269Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Init models","metadata":{}},{"cell_type":"code","source":"original_model, original_model_name, criterion, _optimizer, transform = load_model_effnetb0(model_pth_path=model_file)\n\nmodel_to_unlearn = copy.deepcopy(original_model)\nimport torch.nn as nn\nmodel_to_unlearn = nn.DataParallel(model_to_unlearn, device_ids=[0, 1])\n\nmodel_to_unlearn_name = 'fisher_' + original_model_name","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:39.555298Z","iopub.execute_input":"2025-04-03T17:00:39.555619Z","iopub.status.idle":"2025-04-03T17:00:40.516308Z","shell.execute_reply.started":"2025-04-03T17:00:39.555593Z","shell.execute_reply":"2025-04-03T17:00:40.515325Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Load model...\nInit model...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 132MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Done initializing model.\nModel ID: 132825625794864, Optimizer ID: 132825625795584, Criterion ID: 132825625795536\nDone loading model.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Init data","metadata":{}},{"cell_type":"code","source":"data_root = Path('/kaggle/input/animal-faces')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:00:40.517592Z","iopub.execute_input":"2025-04-03T17:00:40.518362Z","iopub.status.idle":"2025-04-03T17:00:40.522461Z","shell.execute_reply.started":"2025-04-03T17:00:40.518315Z","shell.execute_reply":"2025-04-03T17:00:40.521643Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(root=data_root/'afhq/train', transform=transform)\ntest_dataset = datasets.ImageFolder(root=data_root/'afhq/val', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:00:40.523616Z","iopub.execute_input":"2025-04-03T17:00:40.523885Z","iopub.status.idle":"2025-04-03T17:01:13.764819Z","shell.execute_reply.started":"2025-04-03T17:00:40.523858Z","shell.execute_reply":"2025-04-03T17:01:13.763963Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"unlearn_indices, _unlearn_loader = create_unlearning_dataloader(samples_to_unlearn_file, train_dataset, batch_size = MINI_BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:01:13.765912Z","iopub.execute_input":"2025-04-03T17:01:13.766245Z","iopub.status.idle":"2025-04-03T17:01:13.776399Z","shell.execute_reply.started":"2025-04-03T17:01:13.766211Z","shell.execute_reply":"2025-04-03T17:01:13.775399Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# train_loader, _val_loader, test_loader, classes = recreate_dataloaders(\n#     data_splits_file=remaining_dataset_file,\n#     datasets=(train_dataset, test_dataset), \n#     batch_size=BATCH_SIZE)\n\n# unlearn_loader = create_unlearning_dataloader(samples_to_unlearn_file, train_dataset, batch_size = MINI_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:01:13.777607Z","iopub.execute_input":"2025-04-03T17:01:13.777880Z","iopub.status.idle":"2025-04-03T17:01:13.792781Z","shell.execute_reply.started":"2025-04-03T17:01:13.777851Z","shell.execute_reply":"2025-04-03T17:01:13.791846Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### FIM","metadata":{}},{"cell_type":"code","source":"import math\nimport json\nimport torch\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, Subset\n\nfrom utils.utils import DEVICE\n\ndef compute_gradient_on_subset(model, criterion, dataset_subset, batch_size):\n    \"\"\"\n    Compute the average gradient Δ_rem = ∇L(θ, D') over the given dataset_subset.\n    \"\"\"\n    dataloader = DataLoader(dataset_subset, batch_size=batch_size, shuffle=False)\n    \n    grad_dict = {}\n    total_samples = 0\n\n    model.train()\n    for inputs, targets in tqdm(dataloader, desc=\"Computing gradients\"):\n        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n        model.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        current_batch = inputs.size(0)\n        total_samples += current_batch\n        for name, param in model.named_parameters():\n            if param.requires_grad and param.grad is not None:\n                if name not in grad_dict:\n                    grad_dict[name] = param.grad.detach().clone() * current_batch\n                else:\n                    grad_dict[name] += param.grad.detach() * current_batch\n\n    # Average gradients over the entire subset\n    for name in grad_dict:\n        grad_dict[name] /= total_samples\n\n    return grad_dict\n\ndef compute_fisher_on_subset(model, criterion, dataset_subset, batch_size):\n    \"\"\"\n    Compute a diagonal approximation of the Fisher Information Matrix F over the given dataset_subset.\n    It averages the squared gradients.\n    \"\"\"\n    dataloader = DataLoader(dataset_subset, batch_size=batch_size, shuffle=False)\n    fisher_diag = {}\n    total_samples = 0\n\n    model.eval()\n    for inputs, targets in tqdm(dataloader, desc=\"Computing Fisher\"):\n        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n        model.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        current_batch = inputs.size(0)\n        total_samples += current_batch\n        for name, param in model.named_parameters():\n            if param.requires_grad and param.grad is not None:\n                if name not in fisher_diag:\n                    fisher_diag[name] = (param.grad.detach() ** 2) * current_batch\n                else:\n                    fisher_diag[name] += (param.grad.detach() ** 2) * current_batch\n\n    for name in fisher_diag:\n        fisher_diag[name] /= total_samples\n\n    return fisher_diag\n    # for name in fisher_diag:\n    #     fisher_diag[name] /= total_samples\n    # fisher_diag['_total_samples'] = total_samples\n\n    return fisher_diag\n\ndef remove_from_fisher_incrementally(fisher_diag, model, criterion, dataset_removed, batch_size):\n    dataloader = DataLoader(dataset_removed, batch_size=batch_size, shuffle=False)\n    total_removed_samples = 0\n\n    model.eval()\n    for inputs, targets in dataloader:\n        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n        model.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        batch_samples = inputs.size(0)\n        total_removed_samples += batch_samples\n        for name, param in model.named_parameters():\n            if param.requires_grad and param.grad is not None:\n                fisher_diag[name] -= (param.grad.detach() ** 2) * batch_samples\n\n    total_samples_remaining = fisher_diag['_total_samples'] - total_removed_samples\n    for name in fisher_diag:\n        if name != '_total_samples':\n            fisher_diag[name] = torch.clamp(fisher_diag[name], min=1e-8)\n            fisher_diag[name] /= total_samples_remaining\n    fisher_diag['_total_samples'] = total_samples_remaining\n\n    return fisher_diag\n\ndef iterative_fisher_unlearn(model, criterion, full_dataset, removal_indices, sigma, deletion_batch_size, compute_batch_size, eps, max_norm):\n    \"\"\"\n    Implements the iterative Fisher unlearning procedure following theory:\n    \n    Inputs:\n      - model: a pretrained PyTorch model (trained on full dataset D).\n      - criterion: loss function (e.g., CrossEntropyLoss).\n      - full_dataset: the full training dataset D (e.g., MNIST training set).\n      - removal_indices: list of indices (from the JSON file) to be deleted (Dₘ). E.g., 6000 samples.\n      - sigma: noise parameter σ.\n      - deletion_batch_size: desired mini-batch size for deletion (m′). E.g., 1000.\n      - compute_batch_size: batch size used when computing gradients/Fisher (BATCH_SIZE).\n      - eps: for numerical stability\n    \n    Procedure:\n      1. Let current_indices = set(range(len(full_dataset))).\n      2. Partition removal_indices into mini-batches of size deletion_batch_size.\n      3. For each mini-batch, update current_indices by removing those indices.\n      4. Create a Subset from full_dataset using current_indices (this is D').\n      5. Compute Δ_rem and diagonal Fisher F on D' and update model:\n             θ ← θ − F⁻¹ Δ_rem + σ · F^(–1/4) · ε.\n    \"\"\"\n    full_size = len(full_dataset)\n    current_indices = set(range(full_size))\n\n    # Partition removal_indices into mini-batches, where s = m /m'\n    removal_list = list(removal_indices)\n    num_batches = math.ceil(len(removal_list) / deletion_batch_size)\n    partitioned_removals = [removal_list[i * deletion_batch_size : (i + 1) * deletion_batch_size] for i in range(num_batches)]\n    print(f\"Total deletion samples: {len(removal_list)}; partitioned into {num_batches} mini-batches (each up to {deletion_batch_size} samples).\")\n\n    # NEWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n    # fisher_diag = compute_fisher_on_subset(model, criterion, full_dataset, compute_batch_size)\n    # NEWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n    # Iterate over each deletion mini-batch\n    for i, batch in enumerate(tqdm(partitioned_removals, desc=\"Fisher step over mini-batches\")):\n        # Remove the current batch of indices from current_indices\n        current_indices -= set(batch)\n        updated_indices = sorted(list(current_indices))\n        # Create a Subset corresponding to the updated dataset D' = D \\ (deleted so far)\n        dataset_remaining = Subset(full_dataset, updated_indices)\n        print(f\"Iteration {i+1}/{num_batches}: Remaining dataset size = {len(dataset_remaining)}\")\n        # NEWWWWWWWWWWWWWWWWWWWWWWWWWW\n        # dataset_removed = Subset(full_dataset, batch)\n        # fisher_diag = remove_from_fisher_incrementally(fisher_diag, model, criterion, dataset_removed, compute_batch_size)\n        # NEWWWWWWWWWWWWWWWWWWWWWWWWWWW\n        # Compute the average gradient and diagonal Fisher on D'\n        grad_dict = compute_gradient_on_subset(model, criterion, dataset_remaining, compute_batch_size)\n        fisher_diag = compute_fisher_on_subset(model, criterion, dataset_remaining, compute_batch_size)\n        # Update model parameters using the Newton correction and noise injection\n        with torch.no_grad():\n            for name in grad_dict:\n                grad = grad_dict[name]\n                norm = grad.norm(2).item()\n                grad_min = grad.min().item()\n                grad_max = grad.max().item()\n                grad_mean = grad.mean().item()\n                grad_std = grad.std().item()\n                print(f\"[Raw] Param {name}: norm = {norm:.4e}, min = {grad_min:.4e}, max = {grad_max:.4e}, mean = {grad_mean:.4e}, std = {grad_std:.4e}\")\n            \n            # First, compute and clip gradients, and monitor norms\n            total_grad_norm_before = 0.0\n            total_grad_norm_after = 0.0\n            for name in grad_dict:\n                norm_before = grad_dict[name].norm(2)\n                total_grad_norm_before += norm_before.item()\n                if norm_before > max_norm:\n                    grad_dict[name] = grad_dict[name] * (max_norm / norm_before)\n                norm_after = grad_dict[name].norm(2)\n                total_grad_norm_after += norm_after.item()\n            \n            print(f\"Iteration {i+1}: Total gradient norm before clipping = {total_grad_norm_before:.4f}\")\n            print(f\"Iteration {i+1}: Total gradient norm after clipping  = {total_grad_norm_after:.4f}\")\n            \n            # Now, update model parameters using the clipped gradients and monitor the Newton update norm\n            total_update_norm = 0.0\n            for name, param in model.named_parameters():\n                if param.requires_grad:\n                    inv_fisher = (fisher_diag[name] + eps).pow(-1)\n                    newton_update = inv_fisher * grad_dict[name]\n                    total_update_norm += newton_update.norm(2).item()\n                    param.data = param.data - newton_update\n\n                    inv_fisher_quarter = (fisher_diag[name] + eps).pow(-0.25)\n                    noise = torch.randn_like(param.data)\n                    param.data = param.data + sigma * inv_fisher_quarter * noise\n\n            print(f\"Iteration {i+1}: Total Newton update norm = {total_update_norm:.4f}\")\n        print(f\"Iteration {i+1}/{num_batches} update completed.\")\n        \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:01:13.794261Z","iopub.execute_input":"2025-04-03T17:01:13.794603Z","iopub.status.idle":"2025-04-03T17:01:13.817371Z","shell.execute_reply.started":"2025-04-03T17:01:13.794573Z","shell.execute_reply":"2025-04-03T17:01:13.816860Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import time\nstart_time = time.perf_counter()\n\nunlearned_model = iterative_fisher_unlearn(\n    model_to_unlearn,\n    criterion,\n    train_dataset,\n    unlearn_indices,\n    SIGMA,\n    deletion_batch_size=MINI_BATCH_SIZE,\n    compute_batch_size=BATCH_SIZE,\n    eps=EPS,\n    max_norm=MAX_NORM,\n)\n\nend_time = time.perf_counter()  # End timer\nelapsed_time = end_time - start_time\n\nprint(f\"Execution time: {elapsed_time:.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:01:13.818650Z","iopub.execute_input":"2025-04-03T17:01:13.819000Z","iopub.status.idle":"2025-04-03T17:08:49.805441Z","shell.execute_reply.started":"2025-04-03T17:01:13.818961Z","shell.execute_reply":"2025-04-03T17:08:49.804543Z"}},"outputs":[{"name":"stdout","text":"Total deletion samples: 4389; partitioned into 2 mini-batches (each up to 4096 samples).\n","output_type":"stream"},{"name":"stderr","text":"Fisher step over mini-batches:   0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1/2: Remaining dataset size = 10534\n","output_type":"stream"},{"name":"stderr","text":"\nComputing gradients:   0%|          | 0/42 [00:00<?, ?it/s]\u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n\nComputing gradients:   2%|▏         | 1/42 [00:07<05:12,  7.61s/it]\u001b[A\nComputing gradients:   5%|▍         | 2/42 [00:11<03:41,  5.54s/it]\u001b[A\nComputing gradients:   7%|▋         | 3/42 [00:15<03:12,  4.93s/it]\u001b[A\nComputing gradients:  10%|▉         | 4/42 [00:20<03:00,  4.75s/it]\u001b[A\nComputing gradients:  12%|█▏        | 5/42 [00:24<02:47,  4.52s/it]\u001b[A\nComputing gradients:  14%|█▍        | 6/42 [00:28<02:38,  4.41s/it]\u001b[A\nComputing gradients:  17%|█▋        | 7/42 [00:32<02:31,  4.33s/it]\u001b[A\nComputing gradients:  19%|█▉        | 8/42 [00:36<02:23,  4.23s/it]\u001b[A\nComputing gradients:  21%|██▏       | 9/42 [00:41<02:20,  4.24s/it]\u001b[A\nComputing gradients:  24%|██▍       | 10/42 [00:44<02:09,  4.05s/it]\u001b[A\nComputing gradients:  26%|██▌       | 11/42 [00:48<02:03,  3.98s/it]\u001b[A\nComputing gradients:  29%|██▊       | 12/42 [00:52<01:58,  3.94s/it]\u001b[A\nComputing gradients:  31%|███       | 13/42 [00:56<01:51,  3.84s/it]\u001b[A\nComputing gradients:  33%|███▎      | 14/42 [00:59<01:46,  3.82s/it]\u001b[A\nComputing gradients:  36%|███▌      | 15/42 [01:03<01:42,  3.79s/it]\u001b[A\nComputing gradients:  38%|███▊      | 16/42 [01:07<01:38,  3.80s/it]\u001b[A\nComputing gradients:  40%|████      | 17/42 [01:11<01:35,  3.82s/it]\u001b[A\nComputing gradients:  43%|████▎     | 18/42 [01:14<01:30,  3.79s/it]\u001b[A\nComputing gradients:  45%|████▌     | 19/42 [01:18<01:28,  3.87s/it]\u001b[A\nComputing gradients:  48%|████▊     | 20/42 [01:22<01:24,  3.86s/it]\u001b[A\nComputing gradients:  50%|█████     | 21/42 [01:26<01:21,  3.88s/it]\u001b[A\nComputing gradients:  52%|█████▏    | 22/42 [01:30<01:17,  3.88s/it]\u001b[A\nComputing gradients:  55%|█████▍    | 23/42 [01:34<01:13,  3.87s/it]\u001b[A\nComputing gradients:  57%|█████▋    | 24/42 [01:38<01:09,  3.84s/it]\u001b[A\nComputing gradients:  60%|█████▉    | 25/42 [01:42<01:05,  3.85s/it]\u001b[A\nComputing gradients:  62%|██████▏   | 26/42 [01:46<01:02,  3.89s/it]\u001b[A\nComputing gradients:  64%|██████▍   | 27/42 [01:50<00:58,  3.90s/it]\u001b[A\nComputing gradients:  67%|██████▋   | 28/42 [01:53<00:53,  3.84s/it]\u001b[A\nComputing gradients:  69%|██████▉   | 29/42 [01:57<00:49,  3.80s/it]\u001b[A\nComputing gradients:  71%|███████▏  | 30/42 [02:01<00:45,  3.78s/it]\u001b[A\nComputing gradients:  74%|███████▍  | 31/42 [02:05<00:41,  3.79s/it]\u001b[A\nComputing gradients:  76%|███████▌  | 32/42 [02:08<00:37,  3.78s/it]\u001b[A\nComputing gradients:  79%|███████▊  | 33/42 [02:12<00:34,  3.81s/it]\u001b[A\nComputing gradients:  81%|████████  | 34/42 [02:16<00:31,  3.90s/it]\u001b[A\nComputing gradients:  83%|████████▎ | 35/42 [02:21<00:28,  4.01s/it]\u001b[A\nComputing gradients:  86%|████████▌ | 36/42 [02:25<00:24,  4.02s/it]\u001b[A\nComputing gradients:  88%|████████▊ | 37/42 [02:29<00:20,  4.06s/it]\u001b[A\nComputing gradients:  90%|█████████ | 38/42 [02:33<00:16,  4.13s/it]\u001b[A\nComputing gradients:  93%|█████████▎| 39/42 [02:37<00:12,  4.09s/it]\u001b[A\nComputing gradients:  95%|█████████▌| 40/42 [02:41<00:08,  4.14s/it]\u001b[A\nComputing gradients:  98%|█████████▊| 41/42 [02:45<00:04,  4.15s/it]\u001b[A\nComputing gradients: 100%|██████████| 42/42 [02:46<00:00,  3.97s/it]\u001b[A\n\nComputing Fisher:   0%|          | 0/42 [00:00<?, ?it/s]\u001b[A\nComputing Fisher:   2%|▏         | 1/42 [00:02<01:53,  2.76s/it]\u001b[A\nComputing Fisher:   5%|▍         | 2/42 [00:05<01:43,  2.59s/it]\u001b[A\nComputing Fisher:   7%|▋         | 3/42 [00:07<01:35,  2.45s/it]\u001b[A\nComputing Fisher:  10%|▉         | 4/42 [00:09<01:32,  2.44s/it]\u001b[A\nComputing Fisher:  12%|█▏        | 5/42 [00:12<01:29,  2.42s/it]\u001b[A\nComputing Fisher:  14%|█▍        | 6/42 [00:14<01:26,  2.40s/it]\u001b[A\nComputing Fisher:  17%|█▋        | 7/42 [00:17<01:24,  2.41s/it]\u001b[A\nComputing Fisher:  19%|█▉        | 8/42 [00:19<01:23,  2.46s/it]\u001b[A\nComputing Fisher:  21%|██▏       | 9/42 [00:22<01:22,  2.51s/it]\u001b[A\nComputing Fisher:  24%|██▍       | 10/42 [00:24<01:19,  2.49s/it]\u001b[A\nComputing Fisher:  26%|██▌       | 11/42 [00:27<01:16,  2.48s/it]\u001b[A\nComputing Fisher:  29%|██▊       | 12/42 [00:29<01:14,  2.48s/it]\u001b[A\nComputing Fisher:  31%|███       | 13/42 [00:32<01:15,  2.61s/it]\u001b[A\nComputing Fisher:  33%|███▎      | 14/42 [00:35<01:11,  2.56s/it]\u001b[A\nComputing Fisher:  36%|███▌      | 15/42 [00:37<01:08,  2.54s/it]\u001b[A\nComputing Fisher:  38%|███▊      | 16/42 [00:39<01:05,  2.50s/it]\u001b[A\nComputing Fisher:  40%|████      | 17/42 [00:42<01:02,  2.49s/it]\u001b[A\nComputing Fisher:  43%|████▎     | 18/42 [00:44<00:59,  2.48s/it]\u001b[A\nComputing Fisher:  45%|████▌     | 19/42 [00:47<00:57,  2.48s/it]\u001b[A\nComputing Fisher:  48%|████▊     | 20/42 [00:49<00:53,  2.45s/it]\u001b[A\nComputing Fisher:  50%|█████     | 21/42 [00:52<00:51,  2.45s/it]\u001b[A\nComputing Fisher:  52%|█████▏    | 22/42 [00:54<00:49,  2.45s/it]\u001b[A\nComputing Fisher:  55%|█████▍    | 23/42 [00:57<00:46,  2.47s/it]\u001b[A\nComputing Fisher:  57%|█████▋    | 24/42 [00:59<00:43,  2.43s/it]\u001b[A\nComputing Fisher:  60%|█████▉    | 25/42 [01:02<00:42,  2.48s/it]\u001b[A\nComputing Fisher:  62%|██████▏   | 26/42 [01:05<00:41,  2.61s/it]\u001b[A\nComputing Fisher:  64%|██████▍   | 27/42 [01:07<00:37,  2.52s/it]\u001b[A\nComputing Fisher:  67%|██████▋   | 28/42 [01:09<00:34,  2.45s/it]\u001b[A\nComputing Fisher:  69%|██████▉   | 29/42 [01:12<00:31,  2.46s/it]\u001b[A\nComputing Fisher:  71%|███████▏  | 30/42 [01:14<00:28,  2.40s/it]\u001b[A\nComputing Fisher:  74%|███████▍  | 31/42 [01:16<00:26,  2.38s/it]\u001b[A\nComputing Fisher:  76%|███████▌  | 32/42 [01:19<00:23,  2.38s/it]\u001b[A\nComputing Fisher:  79%|███████▊  | 33/42 [01:21<00:21,  2.44s/it]\u001b[A\nComputing Fisher:  81%|████████  | 34/42 [01:24<00:19,  2.43s/it]\u001b[A\nComputing Fisher:  83%|████████▎ | 35/42 [01:26<00:16,  2.42s/it]\u001b[A\nComputing Fisher:  86%|████████▌ | 36/42 [01:28<00:14,  2.43s/it]\u001b[A\nComputing Fisher:  88%|████████▊ | 37/42 [01:31<00:12,  2.45s/it]\u001b[A\nComputing Fisher:  90%|█████████ | 38/42 [01:33<00:09,  2.49s/it]\u001b[A\nComputing Fisher:  93%|█████████▎| 39/42 [01:36<00:07,  2.60s/it]\u001b[A\nComputing Fisher:  95%|█████████▌| 40/42 [01:39<00:05,  2.54s/it]\u001b[A\nComputing Fisher:  98%|█████████▊| 41/42 [01:41<00:02,  2.51s/it]\u001b[A\nComputing Fisher: 100%|██████████| 42/42 [01:42<00:00,  2.43s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"[Raw] Param module.features.0.0.weight: norm = 3.3150e-01, min = -2.9391e-02, max = 4.7486e-02, mean = 1.0985e-03, std = 1.1231e-02\n[Raw] Param module.features.0.1.weight: norm = 1.8904e-02, min = -8.9379e-03, max = 1.5036e-02, mean = 5.0658e-04, std = 3.3560e-03\n[Raw] Param module.features.0.1.bias: norm = 9.9462e-03, min = -3.6006e-03, max = 7.5153e-03, mean = 7.7016e-05, std = 1.7847e-03\n[Raw] Param module.features.1.0.block.0.0.weight: norm = 1.6808e-01, min = -2.1375e-02, max = 4.1554e-02, mean = 2.0867e-03, std = 9.6990e-03\n[Raw] Param module.features.1.0.block.0.1.weight: norm = 1.6751e-02, min = -6.9406e-03, max = 6.9170e-03, mean = 2.2151e-04, std = 3.0001e-03\n[Raw] Param module.features.1.0.block.0.1.bias: norm = 8.3034e-03, min = -2.5651e-03, max = 5.8433e-03, mean = 3.3131e-04, std = 1.4528e-03\n[Raw] Param module.features.1.0.block.1.fc1.weight: norm = 8.3435e-02, min = -2.7570e-02, max = 8.4323e-03, mean = -2.0893e-03, std = 4.7872e-03\n[Raw] Param module.features.1.0.block.1.fc1.bias: norm = 3.1498e-03, min = -2.4633e-03, max = 7.2796e-04, mean = -6.8339e-04, std = 9.4000e-04\n[Raw] Param module.features.1.0.block.1.fc2.weight: norm = 1.7548e-02, min = -5.8779e-03, max = 5.3851e-03, mean = -5.2371e-05, std = 1.0976e-03\n[Raw] Param module.features.1.0.block.1.fc2.bias: norm = 1.8978e-02, min = -1.2788e-02, max = 6.2912e-03, mean = 9.2854e-05, std = 3.4073e-03\n[Raw] Param module.features.1.0.block.2.0.weight: norm = 1.1250e-01, min = -1.9484e-02, max = 2.3247e-02, mean = 2.6530e-04, std = 4.9698e-03\n[Raw] Param module.features.1.0.block.2.1.weight: norm = 1.4430e-02, min = -8.9161e-03, max = 7.6005e-03, mean = -7.2837e-05, std = 3.7250e-03\n[Raw] Param module.features.1.0.block.2.1.bias: norm = 9.6123e-09, min = -4.5767e-09, max = 6.0794e-09, mean = 6.0505e-10, std = 2.4019e-09\n[Raw] Param module.features.2.0.block.0.0.weight: norm = 1.3066e-01, min = -1.4027e-02, max = 2.3164e-02, mean = 2.0856e-05, std = 3.3348e-03\n[Raw] Param module.features.2.0.block.0.1.weight: norm = 7.3530e-03, min = -3.0701e-03, max = 3.4470e-03, mean = 3.8062e-05, std = 7.5343e-04\n[Raw] Param module.features.2.0.block.0.1.bias: norm = 7.5832e-03, min = -4.4633e-03, max = 2.9406e-03, mean = -3.5143e-05, std = 7.7721e-04\n[Raw] Param module.features.2.0.block.1.0.weight: norm = 7.6836e-02, min = -7.9334e-03, max = 9.4804e-03, mean = 1.9909e-04, std = 2.6079e-03\n[Raw] Param module.features.2.0.block.1.1.weight: norm = 1.2336e-02, min = -4.5192e-03, max = 4.7247e-03, mean = -5.5404e-05, std = 1.2644e-03\n[Raw] Param module.features.2.0.block.1.1.bias: norm = 4.6991e-03, min = -1.2136e-03, max = 2.2221e-03, mean = -2.8076e-05, std = 4.8129e-04\n[Raw] Param module.features.2.0.block.2.fc1.weight: norm = 3.6920e-02, min = -1.2405e-02, max = 6.1500e-03, mean = -3.5675e-04, std = 1.8524e-03\n[Raw] Param module.features.2.0.block.2.fc1.bias: norm = 9.6831e-04, min = -7.9271e-04, max = 4.2099e-04, mean = -1.3076e-04, std = 5.3828e-04\n[Raw] Param module.features.2.0.block.2.fc2.weight: norm = 5.1826e-02, min = -9.0208e-03, max = 2.8645e-02, mean = 1.5757e-05, std = 2.6481e-03\n[Raw] Param module.features.2.0.block.2.fc2.bias: norm = 1.4067e-02, min = -5.8421e-03, max = 2.9040e-03, mean = 6.9640e-05, std = 1.4415e-03\n[Raw] Param module.features.2.0.block.3.0.weight: norm = 1.4790e-01, min = -1.2992e-02, max = 1.2815e-02, mean = 2.7538e-05, std = 3.0818e-03\n[Raw] Param module.features.2.0.block.3.1.weight: norm = 1.2006e-02, min = -6.8481e-03, max = 7.0505e-03, mean = 6.4812e-05, std = 2.5026e-03\n[Raw] Param module.features.2.0.block.3.1.bias: norm = 3.2013e-09, min = -2.0030e-09, max = 8.2806e-10, mean = -1.3247e-10, std = 6.5366e-10\n[Raw] Param module.features.2.1.block.0.0.weight: norm = 1.3234e-01, min = -1.1919e-02, max = 1.7232e-02, mean = 2.9071e-06, std = 2.2516e-03\n[Raw] Param module.features.2.1.block.0.1.weight: norm = 1.5725e-02, min = -3.3205e-03, max = 1.1115e-02, mean = 1.6906e-04, std = 1.3040e-03\n[Raw] Param module.features.2.1.block.0.1.bias: norm = 1.3069e-02, min = -4.3975e-03, max = 5.6630e-03, mean = 2.5233e-05, std = 1.0926e-03\n[Raw] Param module.features.2.1.block.1.0.weight: norm = 1.4760e-01, min = -2.9841e-02, max = 1.7217e-02, mean = 1.4193e-04, std = 4.0992e-03\n[Raw] Param module.features.2.1.block.1.1.weight: norm = 2.2229e-02, min = -1.0095e-02, max = 5.6282e-03, mean = -2.7263e-05, std = 1.8586e-03\n[Raw] Param module.features.2.1.block.1.1.bias: norm = 9.6701e-03, min = -3.4100e-03, max = 3.1117e-03, mean = -6.5525e-05, std = 8.0598e-04\n[Raw] Param module.features.2.1.block.2.fc1.weight: norm = 5.1388e-02, min = -1.0140e-02, max = 2.0947e-03, mean = -4.9280e-04, std = 1.6783e-03\n[Raw] Param module.features.2.1.block.2.fc1.bias: norm = 4.4806e-03, min = -4.2666e-03, max = 8.7833e-04, mean = -7.1730e-04, std = 1.8433e-03\n[Raw] Param module.features.2.1.block.2.fc2.weight: norm = 4.6234e-02, min = -9.4485e-03, max = 1.6347e-02, mean = -4.9695e-05, std = 1.5731e-03\n[Raw] Param module.features.2.1.block.2.fc2.bias: norm = 7.5652e-03, min = -2.0520e-03, max = 2.7721e-03, mean = -1.6607e-05, std = 6.3241e-04\n[Raw] Param module.features.2.1.block.3.0.weight: norm = 1.2314e-01, min = -1.2877e-02, max = 1.0720e-02, mean = -4.6730e-05, std = 2.0945e-03\n[Raw] Param module.features.2.1.block.3.1.weight: norm = 7.0949e-03, min = -3.0152e-03, max = 2.8904e-03, mean = 1.3830e-04, std = 1.4726e-03\n[Raw] Param module.features.2.1.block.3.1.bias: norm = 2.3746e-03, min = -1.0488e-03, max = 1.0919e-03, mean = -1.5396e-05, std = 4.9489e-04\n[Raw] Param module.features.3.0.block.0.0.weight: norm = 2.0153e-01, min = -2.4190e-02, max = 2.1238e-02, mean = -1.1270e-04, std = 3.4267e-03\n[Raw] Param module.features.3.0.block.0.1.weight: norm = 1.4704e-02, min = -4.1856e-03, max = 6.8170e-03, mean = -8.9316e-05, std = 1.2264e-03\n[Raw] Param module.features.3.0.block.0.1.bias: norm = 2.1593e-02, min = -8.1324e-03, max = 8.9945e-03, mean = 8.2837e-05, std = 1.8038e-03\n[Raw] Param module.features.3.0.block.1.0.weight: norm = 1.2014e-01, min = -1.1978e-02, max = 9.9867e-03, mean = -1.5220e-04, std = 1.9968e-03\n[Raw] Param module.features.3.0.block.1.1.weight: norm = 4.9245e-02, min = -1.5709e-02, max = 1.4700e-02, mean = -1.4737e-05, std = 4.1180e-03\n[Raw] Param module.features.3.0.block.1.1.bias: norm = 1.4055e-02, min = -3.7772e-03, max = 5.1762e-03, mean = -3.1935e-05, std = 1.1749e-03\n[Raw] Param module.features.3.0.block.2.fc1.weight: norm = 8.4626e-02, min = -1.8818e-02, max = 1.1550e-02, mean = -5.5856e-04, std = 2.8260e-03\n[Raw] Param module.features.3.0.block.2.fc1.bias: norm = 3.6034e-03, min = -3.5074e-03, max = 5.4122e-04, mean = -3.6309e-04, std = 1.5616e-03\n[Raw] Param module.features.3.0.block.2.fc2.weight: norm = 7.1486e-02, min = -1.7550e-02, max = 2.2183e-02, mean = 1.1076e-04, std = 2.4309e-03\n[Raw] Param module.features.3.0.block.2.fc2.bias: norm = 9.3663e-03, min = -3.7950e-03, max = 4.5651e-03, mean = 3.2076e-05, std = 7.8259e-04\n[Raw] Param module.features.3.0.block.3.0.weight: norm = 2.3082e-01, min = -2.1856e-02, max = 2.7643e-02, mean = 1.3199e-05, std = 3.0416e-03\n[Raw] Param module.features.3.0.block.3.1.weight: norm = 1.1961e-02, min = -5.5747e-03, max = 3.5020e-03, mean = -1.0830e-05, std = 1.9152e-03\n[Raw] Param module.features.3.0.block.3.1.bias: norm = 1.7223e-09, min = -4.6551e-10, max = 9.9828e-10, mean = 4.5565e-11, std = 2.7190e-10\n[Raw] Param module.features.3.1.block.0.0.weight: norm = 1.7973e-01, min = -2.6767e-02, max = 1.4217e-02, mean = -2.5914e-05, std = 1.8343e-03\n[Raw] Param module.features.3.1.block.0.1.weight: norm = 2.7256e-02, min = -1.5981e-02, max = 8.4432e-03, mean = -1.5994e-04, std = 1.7557e-03\n[Raw] Param module.features.3.1.block.0.1.bias: norm = 2.0338e-02, min = -8.5622e-03, max = 8.1837e-03, mean = -2.7202e-05, std = 1.3152e-03\n[Raw] Param module.features.3.1.block.1.0.weight: norm = 1.5718e-01, min = -1.3613e-02, max = 3.2053e-02, mean = 3.2032e-05, std = 2.0291e-03\n[Raw] Param module.features.3.1.block.1.1.weight: norm = 2.7173e-02, min = -9.2608e-03, max = 8.1712e-03, mean = -4.0557e-05, std = 1.7572e-03\n[Raw] Param module.features.3.1.block.1.1.bias: norm = 1.6956e-02, min = -4.1831e-03, max = 6.5883e-03, mean = -1.2068e-05, std = 1.0967e-03\n[Raw] Param module.features.3.1.block.2.fc1.weight: norm = 5.7171e-02, min = -7.0420e-03, max = 8.7322e-03, mean = -1.1707e-04, std = 1.1614e-03\n[Raw] Param module.features.3.1.block.2.fc1.bias: norm = 6.8946e-03, min = -2.6919e-03, max = 4.8466e-03, mean = -3.9737e-04, std = 2.2597e-03\n[Raw] Param module.features.3.1.block.2.fc2.weight: norm = 6.1584e-02, min = -9.4632e-03, max = 7.4937e-03, mean = 5.0259e-06, std = 1.2573e-03\n[Raw] Param module.features.3.1.block.2.fc2.bias: norm = 1.1331e-02, min = -3.7147e-03, max = 3.1567e-03, mean = -2.3299e-05, std = 7.3255e-04\n[Raw] Param module.features.3.1.block.3.0.weight: norm = 1.6894e-01, min = -1.5822e-02, max = 2.0771e-02, mean = -2.4740e-05, std = 1.7242e-03\n[Raw] Param module.features.3.1.block.3.1.weight: norm = 1.0321e-02, min = -4.8102e-03, max = 3.9607e-03, mean = 2.6707e-04, std = 1.6303e-03\n[Raw] Param module.features.3.1.block.3.1.bias: norm = 8.7723e-03, min = -4.4994e-03, max = 2.8718e-03, mean = -1.0588e-04, std = 1.4006e-03\n[Raw] Param module.features.4.0.block.0.0.weight: norm = 2.4927e-01, min = -2.7934e-02, max = 2.1003e-02, mean = -4.5790e-05, std = 2.5438e-03\n[Raw] Param module.features.4.0.block.0.1.weight: norm = 2.7685e-02, min = -9.7121e-03, max = 1.1755e-02, mean = -1.4616e-04, std = 1.7848e-03\n[Raw] Param module.features.4.0.block.0.1.bias: norm = 3.8946e-02, min = -1.6436e-02, max = 6.2237e-03, mean = -1.1608e-04, std = 2.5165e-03\n[Raw] Param module.features.4.0.block.1.0.weight: norm = 6.5310e-02, min = -6.0825e-03, max = 6.1841e-03, mean = 1.3052e-05, std = 1.4055e-03\n[Raw] Param module.features.4.0.block.1.1.weight: norm = 6.8932e-02, min = -3.1272e-02, max = 2.1213e-02, mean = -4.5545e-05, std = 4.4586e-03\n[Raw] Param module.features.4.0.block.1.1.bias: norm = 2.2844e-02, min = -4.5690e-03, max = 7.9312e-03, mean = -8.3933e-07, std = 1.4776e-03\n[Raw] Param module.features.4.0.block.2.fc1.weight: norm = 4.3928e-02, min = -5.7465e-03, max = 6.4008e-03, mean = 4.4258e-05, std = 8.9577e-04\n[Raw] Param module.features.4.0.block.2.fc1.bias: norm = 1.0010e-03, min = -5.2997e-04, max = 5.2491e-04, mean = -1.4975e-05, std = 3.3328e-04\n[Raw] Param module.features.4.0.block.2.fc2.weight: norm = 1.6588e-02, min = -5.1770e-03, max = 2.7135e-03, mean = -2.6509e-07, std = 3.3867e-04\n[Raw] Param module.features.4.0.block.2.fc2.bias: norm = 3.4023e-02, min = -1.1082e-02, max = 1.4340e-02, mean = 4.7415e-05, std = 2.2002e-03\n[Raw] Param module.features.4.0.block.3.0.weight: norm = 3.0750e-01, min = -2.9417e-02, max = 2.1333e-02, mean = 1.4730e-05, std = 2.2192e-03\n[Raw] Param module.features.4.0.block.3.1.weight: norm = 1.0619e-02, min = -3.5830e-03, max = 4.3867e-03, mean = -6.5031e-05, std = 1.1930e-03\n[Raw] Param module.features.4.0.block.3.1.bias: norm = 1.3633e-09, min = -5.5485e-10, max = 5.5018e-10, mean = 8.9036e-12, std = 1.5313e-10\n[Raw] Param module.features.4.1.block.0.0.weight: norm = 1.8145e-01, min = -2.0490e-02, max = 2.3477e-02, mean = -2.9711e-06, std = 9.2598e-04\n[Raw] Param module.features.4.1.block.0.1.weight: norm = 1.4589e-02, min = -4.6154e-03, max = 4.2907e-03, mean = -1.6634e-05, std = 6.6639e-04\n[Raw] Param module.features.4.1.block.0.1.bias: norm = 1.0333e-02, min = -2.6438e-03, max = 2.7202e-03, mean = 2.4147e-05, std = 4.7151e-04\n[Raw] Param module.features.4.1.block.1.0.weight: norm = 9.0080e-02, min = -1.1856e-02, max = 1.2732e-02, mean = -2.3012e-05, std = 1.3705e-03\n[Raw] Param module.features.4.1.block.1.1.weight: norm = 2.2133e-02, min = -8.9873e-03, max = 5.6282e-03, mean = 3.7008e-06, std = 1.0113e-03\n[Raw] Param module.features.4.1.block.1.1.bias: norm = 1.3169e-02, min = -2.4391e-03, max = 3.3152e-03, mean = 4.1498e-05, std = 6.0028e-04\n[Raw] Param module.features.4.1.block.2.fc1.weight: norm = 4.2963e-02, min = -4.7887e-03, max = 4.0542e-03, mean = 1.7993e-05, std = 4.3814e-04\n[Raw] Param module.features.4.1.block.2.fc1.bias: norm = 3.7823e-03, min = -1.5952e-03, max = 1.7007e-03, mean = 7.7491e-05, std = 8.6406e-04\n[Raw] Param module.features.4.1.block.2.fc2.weight: norm = 9.7616e-02, min = -1.3784e-02, max = 1.1581e-02, mean = -2.4832e-05, std = 9.9603e-04\n[Raw] Param module.features.4.1.block.2.fc2.bias: norm = 7.3796e-03, min = -2.0279e-03, max = 1.7042e-03, mean = -1.0789e-05, std = 3.3701e-04\n[Raw] Param module.features.4.1.block.3.0.weight: norm = 1.7423e-01, min = -1.5639e-02, max = 1.1351e-02, mean = 1.7593e-06, std = 8.8911e-04\n[Raw] Param module.features.4.1.block.3.1.weight: norm = 1.0305e-02, min = -5.0599e-03, max = 3.0644e-03, mean = -3.9267e-05, std = 1.1588e-03\n[Raw] Param module.features.4.1.block.3.1.bias: norm = 1.6702e-03, min = -5.2794e-04, max = 4.2499e-04, mean = 6.9449e-06, std = 1.8779e-04\n[Raw] Param module.features.4.2.block.0.0.weight: norm = 1.8267e-01, min = -1.0681e-02, max = 1.2272e-02, mean = -4.0832e-06, std = 9.3218e-04\n[Raw] Param module.features.4.2.block.0.1.weight: norm = 1.6345e-02, min = -7.1466e-03, max = 2.0268e-03, mean = -3.6801e-05, std = 7.4592e-04\n[Raw] Param module.features.4.2.block.0.1.bias: norm = 1.2092e-02, min = -4.5541e-03, max = 4.4143e-03, mean = 3.2038e-05, std = 5.5158e-04\n[Raw] Param module.features.4.2.block.1.0.weight: norm = 8.6844e-02, min = -1.1236e-02, max = 1.2739e-02, mean = -6.9374e-06, std = 1.3214e-03\n[Raw] Param module.features.4.2.block.1.1.weight: norm = 3.1742e-02, min = -1.3743e-02, max = 8.9640e-03, mean = 1.9156e-05, std = 1.4502e-03\n[Raw] Param module.features.4.2.block.1.1.bias: norm = 1.6863e-02, min = -2.7414e-03, max = 3.6164e-03, mean = 5.4026e-05, std = 7.6857e-04\n[Raw] Param module.features.4.2.block.2.fc1.weight: norm = 4.7029e-02, min = -3.9220e-03, max = 4.1151e-03, mean = 8.9874e-06, std = 4.7993e-04\n[Raw] Param module.features.4.2.block.2.fc1.bias: norm = 5.8044e-03, min = -1.7677e-03, max = 2.6273e-03, mean = 7.7355e-05, std = 1.3293e-03\n[Raw] Param module.features.4.2.block.2.fc2.weight: norm = 8.7041e-02, min = -9.1811e-03, max = 8.2984e-03, mean = 1.8612e-06, std = 8.8840e-04\n[Raw] Param module.features.4.2.block.2.fc2.bias: norm = 8.9216e-03, min = -2.1306e-03, max = 1.5869e-03, mean = -1.1862e-06, std = 4.0764e-04\n[Raw] Param module.features.4.2.block.3.0.weight: norm = 1.8018e-01, min = -2.4280e-02, max = 1.9837e-02, mean = 1.5870e-05, std = 9.1935e-04\n[Raw] Param module.features.4.2.block.3.1.weight: norm = 8.2430e-03, min = -1.9098e-03, max = 2.9785e-03, mean = 2.2540e-04, std = 8.9924e-04\n[Raw] Param module.features.4.2.block.3.1.bias: norm = 2.9358e-03, min = -9.9139e-04, max = 6.0328e-04, mean = -2.3083e-05, std = 3.2948e-04\n[Raw] Param module.features.5.0.block.0.0.weight: norm = 3.1918e-01, min = -2.5156e-02, max = 3.4834e-02, mean = -1.7549e-05, std = 1.6287e-03\n[Raw] Param module.features.5.0.block.0.1.weight: norm = 4.8339e-02, min = -3.8121e-02, max = 1.0561e-02, mean = -1.0565e-04, std = 2.2061e-03\n[Raw] Param module.features.5.0.block.0.1.bias: norm = 5.6468e-02, min = -2.0219e-02, max = 1.8093e-02, mean = -1.8608e-05, std = 2.5800e-03\n[Raw] Param module.features.5.0.block.1.0.weight: norm = 2.8434e-01, min = -1.4661e-02, max = 1.7049e-02, mean = 2.0028e-04, std = 2.5880e-03\n[Raw] Param module.features.5.0.block.1.1.weight: norm = 6.4379e-02, min = -1.2508e-02, max = 1.6805e-02, mean = -1.2447e-04, std = 2.9389e-03\n[Raw] Param module.features.5.0.block.1.1.bias: norm = 3.3054e-02, min = -6.4176e-03, max = 6.7132e-03, mean = 8.2703e-06, std = 1.5103e-03\n[Raw] Param module.features.5.0.block.2.fc1.weight: norm = 1.0810e-01, min = -9.7908e-03, max = 9.5841e-03, mean = -1.3076e-04, std = 1.0955e-03\n[Raw] Param module.features.5.0.block.2.fc1.bias: norm = 7.9018e-03, min = -5.2516e-03, max = 2.1077e-03, mean = -3.6232e-04, std = 1.7743e-03\n[Raw] Param module.features.5.0.block.2.fc2.weight: norm = 1.6326e-01, min = -2.1289e-02, max = 1.5794e-02, mean = 9.6377e-05, std = 1.6635e-03\n[Raw] Param module.features.5.0.block.2.fc2.bias: norm = 1.5326e-02, min = -4.4523e-03, max = 3.8209e-03, mean = 7.5300e-05, std = 6.9619e-04\n[Raw] Param module.features.5.0.block.3.0.weight: norm = 3.5415e-01, min = -1.6885e-02, max = 1.5190e-02, mean = -1.8428e-05, std = 1.5273e-03\n[Raw] Param module.features.5.0.block.3.1.weight: norm = 1.1659e-02, min = -3.4197e-03, max = 3.0746e-03, mean = -3.5163e-05, std = 1.1061e-03\n[Raw] Param module.features.5.0.block.3.1.bias: norm = 1.2093e-09, min = -3.2053e-10, max = 2.5330e-10, mean = -3.9536e-12, std = 1.1471e-10\n[Raw] Param module.features.5.1.block.0.0.weight: norm = 2.5965e-01, min = -1.0141e-02, max = 1.2798e-02, mean = 2.6518e-06, std = 9.4643e-04\n[Raw] Param module.features.5.1.block.0.1.weight: norm = 1.7794e-02, min = -4.2833e-03, max = 5.9520e-03, mean = 1.9920e-05, std = 6.8665e-04\n[Raw] Param module.features.5.1.block.0.1.bias: norm = 2.3189e-02, min = -9.6194e-03, max = 5.5916e-03, mean = 1.2450e-05, std = 8.9513e-04\n[Raw] Param module.features.5.1.block.1.0.weight: norm = 1.3398e-01, min = -8.2669e-03, max = 1.0708e-02, mean = 3.0185e-05, std = 1.0333e-03\n[Raw] Param module.features.5.1.block.1.1.weight: norm = 3.3040e-02, min = -8.0660e-03, max = 1.0566e-02, mean = -4.0024e-05, std = 1.2748e-03\n[Raw] Param module.features.5.1.block.1.1.bias: norm = 1.5425e-02, min = -2.4511e-03, max = 2.5551e-03, mean = -1.9998e-05, std = 5.9512e-04\n[Raw] Param module.features.5.1.block.2.fc1.weight: norm = 7.3017e-02, min = -4.7573e-03, max = 4.7180e-03, mean = -7.2686e-05, std = 5.2733e-04\n[Raw] Param module.features.5.1.block.2.fc1.bias: norm = 7.8062e-03, min = -3.0620e-03, max = 2.6331e-03, mean = -4.1157e-04, std = 1.4427e-03\n[Raw] Param module.features.5.1.block.2.fc2.weight: norm = 1.2294e-01, min = -7.5839e-03, max = 1.1381e-02, mean = 6.5084e-06, std = 8.9624e-04\n[Raw] Param module.features.5.1.block.2.fc2.bias: norm = 1.2206e-02, min = -1.8085e-03, max = 3.6335e-03, mean = 6.1468e-06, std = 4.7116e-04\n[Raw] Param module.features.5.1.block.3.0.weight: norm = 2.4437e-01, min = -1.9198e-02, max = 2.2749e-02, mean = -2.5244e-06, std = 8.9076e-04\n[Raw] Param module.features.5.1.block.3.1.weight: norm = 1.4431e-02, min = -4.6684e-03, max = 5.4164e-03, mean = 2.9563e-04, std = 1.3372e-03\n[Raw] Param module.features.5.1.block.3.1.bias: norm = 1.0797e-02, min = -5.7504e-03, max = 2.8304e-03, mean = -8.0304e-05, std = 1.0216e-03\n[Raw] Param module.features.5.2.block.0.0.weight: norm = 2.2617e-01, min = -1.1111e-02, max = 1.0162e-02, mean = -5.0254e-06, std = 8.2439e-04\n[Raw] Param module.features.5.2.block.0.1.weight: norm = 2.5473e-02, min = -1.5260e-02, max = 5.8427e-03, mean = -4.4354e-07, std = 9.8336e-04\n[Raw] Param module.features.5.2.block.0.1.bias: norm = 2.2024e-02, min = -5.4116e-03, max = 1.1486e-02, mean = 2.6137e-05, std = 8.4981e-04\n[Raw] Param module.features.5.2.block.1.0.weight: norm = 1.2531e-01, min = -6.3873e-03, max = 1.0652e-02, mean = 7.4717e-05, std = 9.6396e-04\n[Raw] Param module.features.5.2.block.1.1.weight: norm = 2.8166e-02, min = -8.6198e-03, max = 5.4330e-03, mean = -1.6005e-05, std = 1.0872e-03\n[Raw] Param module.features.5.2.block.1.1.bias: norm = 1.4273e-02, min = -2.5328e-03, max = 2.6565e-03, mean = -1.2154e-05, std = 5.5087e-04\n[Raw] Param module.features.5.2.block.2.fc1.weight: norm = 6.5450e-02, min = -4.9610e-03, max = 5.2584e-03, mean = -1.1063e-05, std = 4.7702e-04\n[Raw] Param module.features.5.2.block.2.fc1.bias: norm = 8.0548e-03, min = -4.1838e-03, max = 2.7744e-03, mean = -1.6052e-05, std = 1.5501e-03\n[Raw] Param module.features.5.2.block.2.fc2.weight: norm = 1.0589e-01, min = -1.2963e-02, max = 9.7578e-03, mean = -3.6755e-06, std = 7.7197e-04\n[Raw] Param module.features.5.2.block.2.fc2.bias: norm = 1.3147e-02, min = -3.6584e-03, max = 2.0560e-03, mean = -5.6742e-07, std = 5.0752e-04\n[Raw] Param module.features.5.2.block.3.0.weight: norm = 2.0817e-01, min = -8.4520e-03, max = 1.0038e-02, mean = -6.1701e-06, std = 7.5877e-04\n[Raw] Param module.features.5.2.block.3.1.weight: norm = 1.2303e-02, min = -3.4465e-03, max = 4.9984e-03, mean = -7.5915e-05, std = 1.1652e-03\n[Raw] Param module.features.5.2.block.3.1.bias: norm = 8.0155e-03, min = -1.7824e-03, max = 3.0265e-03, mean = 1.6276e-04, std = 7.4302e-04\n[Raw] Param module.features.6.0.block.0.0.weight: norm = 4.0658e-01, min = -1.8432e-02, max = 1.5735e-02, mean = 3.0451e-05, std = 1.4817e-03\n[Raw] Param module.features.6.0.block.0.1.weight: norm = 7.3367e-02, min = -1.2464e-02, max = 2.0409e-02, mean = -1.1407e-04, std = 2.8300e-03\n[Raw] Param module.features.6.0.block.0.1.bias: norm = 7.5182e-02, min = -8.2349e-03, max = 3.4442e-02, mean = 1.8868e-04, std = 2.8962e-03\n[Raw] Param module.features.6.0.block.1.0.weight: norm = 1.8897e-01, min = -1.0235e-02, max = 8.3826e-03, mean = 3.7427e-05, std = 1.4575e-03\n[Raw] Param module.features.6.0.block.1.1.weight: norm = 8.1673e-02, min = -8.6576e-03, max = 2.1834e-02, mean = 2.8371e-05, std = 3.1528e-03\n[Raw] Param module.features.6.0.block.1.1.bias: norm = 1.7758e-02, min = -3.1490e-03, max = 5.7178e-03, mean = 4.6455e-05, std = 6.8398e-04\n[Raw] Param module.features.6.0.block.2.fc1.weight: norm = 7.0437e-03, min = -5.9174e-04, max = 8.0045e-04, mean = 1.0880e-05, std = 5.0185e-05\n[Raw] Param module.features.6.0.block.2.fc1.bias: norm = 1.4967e-04, min = -2.9667e-05, max = 1.1138e-04, mean = 9.2715e-06, std = 2.7213e-05\n[Raw] Param module.features.6.0.block.2.fc2.weight: norm = 3.7975e-03, min = -2.0254e-03, max = 1.1828e-03, mean = 2.7663e-07, std = 2.7684e-05\n[Raw] Param module.features.6.0.block.2.fc2.bias: norm = 1.7494e-02, min = -5.7147e-03, max = 1.0646e-02, mean = -1.0624e-05, std = 6.7525e-04\n[Raw] Param module.features.6.0.block.3.0.weight: norm = 4.7043e-01, min = -1.3804e-02, max = 1.4087e-02, mean = -4.5590e-06, std = 1.3097e-03\n[Raw] Param module.features.6.0.block.3.1.weight: norm = 1.5815e-02, min = -3.2291e-03, max = 5.1449e-03, mean = -4.3747e-04, std = 1.0569e-03\n[Raw] Param module.features.6.0.block.3.1.bias: norm = 1.1671e-09, min = -2.7407e-10, max = 2.1373e-10, mean = -2.3623e-12, std = 8.4415e-11\n[Raw] Param module.features.6.1.block.0.0.weight: norm = 3.2971e-01, min = -9.7412e-03, max = 9.8710e-03, mean = 1.1796e-06, std = 7.0107e-04\n[Raw] Param module.features.6.1.block.0.1.weight: norm = 3.1840e-02, min = -5.1247e-03, max = 1.1147e-02, mean = 5.1473e-05, std = 9.3707e-04\n[Raw] Param module.features.6.1.block.0.1.bias: norm = 5.4545e-02, min = -2.0309e-02, max = 7.2116e-03, mean = -4.1099e-05, std = 1.6072e-03\n[Raw] Param module.features.6.1.block.1.0.weight: norm = 1.6647e-01, min = -1.2837e-02, max = 1.1821e-02, mean = 3.9801e-05, std = 9.8015e-04\n[Raw] Param module.features.6.1.block.1.1.weight: norm = 3.1127e-02, min = -4.1946e-03, max = 1.0767e-02, mean = 1.3553e-05, std = 9.1739e-04\n[Raw] Param module.features.6.1.block.1.1.bias: norm = 1.8935e-02, min = -2.8854e-03, max = 3.6568e-03, mean = -1.4422e-06, std = 5.5812e-04\n[Raw] Param module.features.6.1.block.2.fc1.weight: norm = 1.0669e-01, min = -4.9571e-03, max = 6.6340e-03, mean = -3.2687e-05, std = 4.5255e-04\n[Raw] Param module.features.6.1.block.2.fc1.bias: norm = 8.9546e-03, min = -4.4913e-03, max = 1.5826e-03, mean = -2.3747e-04, std = 1.2839e-03\n[Raw] Param module.features.6.1.block.2.fc2.weight: norm = 1.7039e-01, min = -1.4653e-02, max = 1.5314e-02, mean = -1.8516e-06, std = 7.2461e-04\n[Raw] Param module.features.6.1.block.2.fc2.bias: norm = 1.5619e-02, min = -3.7097e-03, max = 3.2321e-03, mean = 4.5680e-07, std = 4.6039e-04\n[Raw] Param module.features.6.1.block.3.0.weight: norm = 3.3716e-01, min = -1.4270e-02, max = 1.0278e-02, mean = 5.4603e-06, std = 7.1689e-04\n[Raw] Param module.features.6.1.block.3.1.weight: norm = 1.9052e-02, min = -3.1764e-03, max = 4.8320e-03, mean = 4.6333e-04, std = 1.2980e-03\n[Raw] Param module.features.6.1.block.3.1.bias: norm = 9.1004e-03, min = -1.8520e-03, max = 1.9325e-03, mean = -1.8175e-05, std = 6.5823e-04\n[Raw] Param module.features.6.2.block.0.0.weight: norm = 3.4999e-01, min = -1.1466e-02, max = 9.9458e-03, mean = 7.5029e-07, std = 7.4418e-04\n[Raw] Param module.features.6.2.block.0.1.weight: norm = 2.8101e-02, min = -4.5534e-03, max = 7.4273e-03, mean = 3.2409e-07, std = 8.2830e-04\n[Raw] Param module.features.6.2.block.0.1.bias: norm = 3.6128e-02, min = -1.9413e-02, max = 6.0501e-03, mean = -1.2350e-05, std = 1.0648e-03\n[Raw] Param module.features.6.2.block.1.0.weight: norm = 1.7126e-01, min = -1.1459e-02, max = 1.0785e-02, mean = 3.5565e-05, std = 1.0085e-03\n[Raw] Param module.features.6.2.block.1.1.weight: norm = 3.2422e-02, min = -7.5264e-03, max = 9.6778e-03, mean = -1.2040e-05, std = 9.5557e-04\n[Raw] Param module.features.6.2.block.1.1.bias: norm = 2.0123e-02, min = -3.4114e-03, max = 4.5901e-03, mean = 4.7560e-06, std = 5.9311e-04\n[Raw] Param module.features.6.2.block.2.fc1.weight: norm = 1.1396e-01, min = -6.7908e-03, max = 5.8878e-03, mean = -1.2808e-05, std = 4.8448e-04\n[Raw] Param module.features.6.2.block.2.fc1.bias: norm = 9.3761e-03, min = -4.1981e-03, max = 2.6188e-03, mean = -1.4251e-04, std = 1.3600e-03\n[Raw] Param module.features.6.2.block.2.fc2.weight: norm = 2.2488e-01, min = -1.3221e-02, max = 2.7309e-02, mean = -6.8070e-07, std = 9.5635e-04\n[Raw] Param module.features.6.2.block.2.fc2.bias: norm = 2.0359e-02, min = -3.0330e-03, max = 4.4473e-03, mean = 4.5173e-06, std = 6.0006e-04\n[Raw] Param module.features.6.2.block.3.0.weight: norm = 3.4692e-01, min = -9.9913e-03, max = 1.0520e-02, mean = 3.7976e-06, std = 7.3764e-04\n[Raw] Param module.features.6.2.block.3.1.weight: norm = 2.2259e-02, min = -7.0956e-03, max = 6.8168e-03, mean = 5.1883e-04, std = 1.5243e-03\n[Raw] Param module.features.6.2.block.3.1.bias: norm = 7.6641e-03, min = -1.5571e-03, max = 1.5462e-03, mean = -2.0791e-05, std = 5.5416e-04\n[Raw] Param module.features.6.3.block.0.0.weight: norm = 3.8006e-01, min = -1.9118e-02, max = 3.0490e-02, mean = 4.6638e-06, std = 8.0811e-04\n[Raw] Param module.features.6.3.block.0.1.weight: norm = 4.5305e-02, min = -1.1041e-02, max = 2.8943e-02, mean = -2.9554e-05, std = 1.3351e-03\n[Raw] Param module.features.6.3.block.0.1.bias: norm = 4.2282e-02, min = -1.6123e-02, max = 1.6783e-02, mean = -4.0613e-05, std = 1.2456e-03\n[Raw] Param module.features.6.3.block.1.0.weight: norm = 1.7965e-01, min = -1.0811e-02, max = 1.8078e-02, mean = 3.5155e-05, std = 1.0580e-03\n[Raw] Param module.features.6.3.block.1.1.weight: norm = 3.9912e-02, min = -1.7868e-02, max = 8.9896e-03, mean = -3.7007e-05, std = 1.1758e-03\n[Raw] Param module.features.6.3.block.1.1.bias: norm = 2.4185e-02, min = -4.1387e-03, max = 4.3803e-03, mean = 2.7368e-05, std = 7.1236e-04\n[Raw] Param module.features.6.3.block.2.fc1.weight: norm = 1.2862e-01, min = -6.3769e-03, max = 7.0205e-03, mean = -4.9914e-05, std = 5.4471e-04\n[Raw] Param module.features.6.3.block.2.fc1.bias: norm = 1.3012e-02, min = -6.2379e-03, max = 2.7859e-03, mean = -4.4907e-04, std = 1.8429e-03\n[Raw] Param module.features.6.3.block.2.fc2.weight: norm = 2.5310e-01, min = -1.9725e-02, max = 2.3886e-02, mean = 9.9577e-07, std = 1.0763e-03\n[Raw] Param module.features.6.3.block.2.fc2.bias: norm = 2.0831e-02, min = -4.5011e-03, max = 5.9637e-03, mean = 4.7347e-06, std = 6.1399e-04\n[Raw] Param module.features.6.3.block.3.0.weight: norm = 3.6030e-01, min = -1.1335e-02, max = 1.4464e-02, mean = 6.5297e-06, std = 7.6609e-04\n[Raw] Param module.features.6.3.block.3.1.weight: norm = 2.0932e-02, min = -3.4067e-03, max = 6.1732e-03, mean = 4.0822e-04, std = 1.4582e-03\n[Raw] Param module.features.6.3.block.3.1.bias: norm = 3.7871e-03, min = -8.9895e-04, max = 8.8223e-04, mean = 2.3100e-05, std = 2.7305e-04\n[Raw] Param module.features.7.0.block.0.0.weight: norm = 5.7291e-01, min = -1.2517e-02, max = 1.7544e-02, mean = 6.5487e-06, std = 1.2182e-03\n[Raw] Param module.features.7.0.block.0.1.weight: norm = 1.6785e-01, min = -4.3476e-02, max = 4.2125e-02, mean = 2.1281e-04, std = 4.9429e-03\n[Raw] Param module.features.7.0.block.0.1.bias: norm = 1.0464e-01, min = -2.0888e-02, max = 2.5374e-02, mean = -3.1333e-04, std = 3.0684e-03\n[Raw] Param module.features.7.0.block.1.0.weight: norm = 2.3408e-01, min = -2.3365e-02, max = 2.1203e-02, mean = 1.2599e-04, std = 2.2955e-03\n[Raw] Param module.features.7.0.block.1.1.weight: norm = 1.0497e-01, min = -7.7415e-03, max = 4.6496e-02, mean = 1.1629e-04, std = 3.0919e-03\n[Raw] Param module.features.7.0.block.1.1.bias: norm = 5.8582e-02, min = -8.5917e-03, max = 1.3174e-02, mean = 3.8215e-04, std = 1.6839e-03\n[Raw] Param module.features.7.0.block.2.fc1.weight: norm = 3.3610e-01, min = -7.4347e-03, max = 1.5153e-02, mean = 2.4896e-04, std = 1.4075e-03\n[Raw] Param module.features.7.0.block.2.fc1.bias: norm = 3.1184e-02, min = -4.6055e-03, max = 1.3183e-02, mean = 2.2846e-03, std = 3.9192e-03\n[Raw] Param module.features.7.0.block.2.fc2.weight: norm = 1.8741e-01, min = -7.0356e-03, max = 2.9580e-02, mean = 2.4682e-06, std = 7.9698e-04\n[Raw] Param module.features.7.0.block.2.fc2.bias: norm = 2.7977e-02, min = -2.4729e-03, max = 8.5153e-03, mean = -1.0501e-04, std = 8.1793e-04\n[Raw] Param module.features.7.0.block.3.0.weight: norm = 5.7854e-01, min = -8.1019e-03, max = 1.1822e-02, mean = 2.8723e-05, std = 9.5244e-04\n[Raw] Param module.features.7.0.block.3.1.weight: norm = 2.7443e-02, min = -7.8267e-03, max = 5.7774e-03, mean = 3.2583e-06, std = 1.5365e-03\n[Raw] Param module.features.7.0.block.3.1.bias: norm = 2.8708e-09, min = -4.2361e-10, max = 8.6353e-10, mean = 1.2288e-11, std = 1.6026e-10\n[Raw] Param module.features.8.0.weight: norm = 5.2143e-01, min = -5.2264e-03, max = 5.4564e-03, mean = 2.7841e-06, std = 8.1473e-04\n[Raw] Param module.features.8.1.weight: norm = 9.2316e-02, min = -9.1649e-04, max = 6.9363e-03, mean = 2.1616e-03, std = 1.4096e-03\n[Raw] Param module.features.8.1.bias: norm = 5.5045e-02, min = -6.1217e-04, max = 4.3328e-03, mean = 1.3026e-03, std = 8.1901e-04\n[Raw] Param module.classifier.1.weight: norm = 3.9922e+00, min = -9.8508e-02, max = 1.7138e-01, mean = 6.2476e-10, std = 6.4432e-02\n[Raw] Param module.classifier.1.bias: norm = 9.0083e-02, min = -3.7666e-02, max = 7.3545e-02, mean = -4.9671e-09, std = 6.3698e-02\nIteration 1: Total gradient norm before clipping = 21.7527\nIteration 1: Total gradient norm after clipping  = 0.0000\n","output_type":"stream"},{"name":"stderr","text":"Fisher step over mini-batches:  50%|█████     | 1/2 [04:29<04:29, 269.38s/it]","output_type":"stream"},{"name":"stdout","text":"Iteration 1: Total Newton update norm = 0.0000\nIteration 1/2 update completed.\nIteration 2/2: Remaining dataset size = 10241\n","output_type":"stream"},{"name":"stderr","text":"\nComputing gradients:   0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\nComputing gradients:   2%|▏         | 1/41 [00:02<01:38,  2.47s/it]\u001b[A\nComputing gradients:   5%|▍         | 2/41 [00:04<01:29,  2.29s/it]\u001b[A\nComputing gradients:   7%|▋         | 3/41 [00:06<01:26,  2.27s/it]\u001b[A\nComputing gradients:  10%|▉         | 4/41 [00:09<01:24,  2.29s/it]\u001b[A\nComputing gradients:  12%|█▏        | 5/41 [00:11<01:22,  2.29s/it]\u001b[A\nComputing gradients:  15%|█▍        | 6/41 [00:13<01:19,  2.28s/it]\u001b[A\nComputing gradients:  17%|█▋        | 7/41 [00:15<01:16,  2.26s/it]\u001b[A\nComputing gradients:  20%|█▉        | 8/41 [00:18<01:15,  2.28s/it]\u001b[A\nComputing gradients:  22%|██▏       | 9/41 [00:20<01:13,  2.29s/it]\u001b[A\nComputing gradients:  24%|██▍       | 10/41 [00:22<01:09,  2.25s/it]\u001b[A\nComputing gradients:  27%|██▋       | 11/41 [00:25<01:12,  2.40s/it]\u001b[A\nComputing gradients:  29%|██▉       | 12/41 [00:27<01:08,  2.35s/it]\u001b[A\nComputing gradients:  32%|███▏      | 13/41 [00:30<01:05,  2.33s/it]\u001b[A\nComputing gradients:  34%|███▍      | 14/41 [00:32<01:01,  2.28s/it]\u001b[A\nComputing gradients:  37%|███▋      | 15/41 [00:34<00:58,  2.24s/it]\u001b[A\nComputing gradients:  39%|███▉      | 16/41 [00:36<00:55,  2.24s/it]\u001b[A\nComputing gradients:  41%|████▏     | 17/41 [00:38<00:53,  2.22s/it]\u001b[A\nComputing gradients:  44%|████▍     | 18/41 [00:41<00:51,  2.25s/it]\u001b[A\nComputing gradients:  46%|████▋     | 19/41 [00:43<00:49,  2.23s/it]\u001b[A\nComputing gradients:  49%|████▉     | 20/41 [00:45<00:47,  2.25s/it]\u001b[A\nComputing gradients:  51%|█████     | 21/41 [00:47<00:45,  2.26s/it]\u001b[A\nComputing gradients:  54%|█████▎    | 22/41 [00:50<00:43,  2.30s/it]\u001b[A\nComputing gradients:  56%|█████▌    | 23/41 [00:52<00:41,  2.31s/it]\u001b[A\nComputing gradients:  59%|█████▊    | 24/41 [00:54<00:39,  2.30s/it]\u001b[A\nComputing gradients:  61%|██████    | 25/41 [00:57<00:39,  2.44s/it]\u001b[A\nComputing gradients:  63%|██████▎   | 26/41 [00:59<00:35,  2.38s/it]\u001b[A\nComputing gradients:  66%|██████▌   | 27/41 [01:02<00:33,  2.39s/it]\u001b[A\nComputing gradients:  68%|██████▊   | 28/41 [01:04<00:31,  2.38s/it]\u001b[A\nComputing gradients:  71%|███████   | 29/41 [01:06<00:28,  2.34s/it]\u001b[A\nComputing gradients:  73%|███████▎  | 30/41 [01:09<00:25,  2.30s/it]\u001b[A\nComputing gradients:  76%|███████▌  | 31/41 [01:11<00:22,  2.29s/it]\u001b[A\nComputing gradients:  78%|███████▊  | 32/41 [01:13<00:20,  2.27s/it]\u001b[A\nComputing gradients:  80%|████████  | 33/41 [01:15<00:17,  2.24s/it]\u001b[A\nComputing gradients:  83%|████████▎ | 34/41 [01:17<00:15,  2.24s/it]\u001b[A\nComputing gradients:  85%|████████▌ | 35/41 [01:20<00:13,  2.23s/it]\u001b[A\nComputing gradients:  88%|████████▊ | 36/41 [01:22<00:11,  2.25s/it]\u001b[A\nComputing gradients:  90%|█████████ | 37/41 [01:24<00:08,  2.23s/it]\u001b[A\nComputing gradients:  93%|█████████▎| 38/41 [01:26<00:06,  2.23s/it]\u001b[A\nComputing gradients:  95%|█████████▌| 39/41 [01:29<00:04,  2.41s/it]\u001b[A\nComputing gradients:  98%|█████████▊| 40/41 [01:31<00:02,  2.34s/it]\u001b[A\nComputing gradients: 100%|██████████| 41/41 [01:32<00:00,  2.26s/it]\u001b[A\n\nComputing Fisher:   0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\nComputing Fisher:   2%|▏         | 1/41 [00:02<01:26,  2.16s/it]\u001b[A\nComputing Fisher:   5%|▍         | 2/41 [00:04<01:26,  2.21s/it]\u001b[A\nComputing Fisher:   7%|▋         | 3/41 [00:06<01:25,  2.26s/it]\u001b[A\nComputing Fisher:  10%|▉         | 4/41 [00:09<01:27,  2.37s/it]\u001b[A\nComputing Fisher:  12%|█▏        | 5/41 [00:11<01:24,  2.36s/it]\u001b[A\nComputing Fisher:  15%|█▍        | 6/41 [00:13<01:22,  2.34s/it]\u001b[A\nComputing Fisher:  17%|█▋        | 7/41 [00:16<01:19,  2.33s/it]\u001b[A\nComputing Fisher:  20%|█▉        | 8/41 [00:18<01:16,  2.33s/it]\u001b[A\nComputing Fisher:  22%|██▏       | 9/41 [00:20<01:14,  2.32s/it]\u001b[A\nComputing Fisher:  24%|██▍       | 10/41 [00:23<01:11,  2.32s/it]\u001b[A\nComputing Fisher:  27%|██▋       | 11/41 [00:25<01:09,  2.32s/it]\u001b[A\nComputing Fisher:  29%|██▉       | 12/41 [00:28<01:11,  2.46s/it]\u001b[A\nComputing Fisher:  32%|███▏      | 13/41 [00:30<01:08,  2.43s/it]\u001b[A\nComputing Fisher:  34%|███▍      | 14/41 [00:33<01:05,  2.44s/it]\u001b[A\nComputing Fisher:  37%|███▋      | 15/41 [00:35<01:01,  2.38s/it]\u001b[A\nComputing Fisher:  39%|███▉      | 16/41 [00:37<00:58,  2.35s/it]\u001b[A\nComputing Fisher:  41%|████▏     | 17/41 [00:39<00:55,  2.33s/it]\u001b[A\nComputing Fisher:  44%|████▍     | 18/41 [00:42<00:54,  2.36s/it]\u001b[A\nComputing Fisher:  46%|████▋     | 19/41 [00:44<00:50,  2.30s/it]\u001b[A\nComputing Fisher:  49%|████▉     | 20/41 [00:46<00:48,  2.29s/it]\u001b[A\nComputing Fisher:  51%|█████     | 21/41 [00:49<00:45,  2.28s/it]\u001b[A\nComputing Fisher:  54%|█████▎    | 22/41 [00:51<00:43,  2.27s/it]\u001b[A\nComputing Fisher:  56%|█████▌    | 23/41 [00:53<00:41,  2.29s/it]\u001b[A\nComputing Fisher:  59%|█████▊    | 24/41 [00:55<00:38,  2.27s/it]\u001b[A\nComputing Fisher:  61%|██████    | 25/41 [00:57<00:35,  2.23s/it]\u001b[A\nComputing Fisher:  63%|██████▎   | 26/41 [01:00<00:35,  2.34s/it]\u001b[A\nComputing Fisher:  66%|██████▌   | 27/41 [01:02<00:32,  2.32s/it]\u001b[A\nComputing Fisher:  68%|██████▊   | 28/41 [01:05<00:29,  2.29s/it]\u001b[A\nComputing Fisher:  71%|███████   | 29/41 [01:07<00:28,  2.34s/it]\u001b[A\nComputing Fisher:  73%|███████▎  | 30/41 [01:09<00:25,  2.30s/it]\u001b[A\nComputing Fisher:  76%|███████▌  | 31/41 [01:12<00:23,  2.31s/it]\u001b[A\nComputing Fisher:  78%|███████▊  | 32/41 [01:14<00:20,  2.32s/it]\u001b[A\nComputing Fisher:  80%|████████  | 33/41 [01:16<00:18,  2.33s/it]\u001b[A\nComputing Fisher:  83%|████████▎ | 34/41 [01:18<00:16,  2.31s/it]\u001b[A\nComputing Fisher:  85%|████████▌ | 35/41 [01:21<00:13,  2.33s/it]\u001b[A\nComputing Fisher:  88%|████████▊ | 36/41 [01:23<00:11,  2.31s/it]\u001b[A\nComputing Fisher:  90%|█████████ | 37/41 [01:25<00:09,  2.31s/it]\u001b[A\nComputing Fisher:  93%|█████████▎| 38/41 [01:28<00:06,  2.31s/it]\u001b[A\nComputing Fisher:  95%|█████████▌| 39/41 [01:30<00:04,  2.39s/it]\u001b[A\nComputing Fisher:  98%|█████████▊| 40/41 [01:33<00:02,  2.43s/it]\u001b[A\nComputing Fisher: 100%|██████████| 41/41 [01:33<00:00,  2.29s/it]\u001b[A\nFisher step over mini-batches: 100%|██████████| 2/2 [07:35<00:00, 227.98s/it]","output_type":"stream"},{"name":"stdout","text":"[Raw] Param module.features.0.0.weight: norm = 6.0849e+06, min = -1.0100e+06, max = 1.1978e+06, mean = 9.0608e+03, std = 2.0693e+05\n[Raw] Param module.features.0.1.weight: norm = 2.8551e+06, min = -9.6014e+05, max = 1.7474e+06, mean = 5.2997e+04, std = 5.0996e+05\n[Raw] Param module.features.0.1.bias: norm = 2.1206e+06, min = -4.2613e+05, max = 1.2971e+06, mean = 7.0823e+04, std = 3.7401e+05\n[Raw] Param module.features.1.0.block.0.0.weight: norm = 8.6482e+06, min = -1.8912e+06, max = 1.9343e+06, mean = -2.5341e+04, std = 5.0986e+05\n[Raw] Param module.features.1.0.block.0.1.weight: norm = 4.1192e+06, min = -2.4484e+06, max = 1.1576e+06, mean = -9.1823e+04, std = 7.3393e+05\n[Raw] Param module.features.1.0.block.0.1.bias: norm = 1.1715e+07, min = -7.2861e+06, max = 4.0507e+06, mean = -2.2717e+05, std = 2.0913e+06\n[Raw] Param module.features.1.0.block.1.fc1.weight: norm = 1.7334e+07, min = -2.0418e+06, max = 9.4518e+06, mean = 2.7844e+05, std = 1.0490e+06\n[Raw] Param module.features.1.0.block.1.fc1.bias: norm = 4.6928e+05, min = -8.7097e+04, max = 4.0315e+05, mean = 7.1841e+04, std = 1.5988e+05\n[Raw] Param module.features.1.0.block.1.fc2.weight: norm = 2.5016e+06, min = -2.4481e+06, max = 1.1007e+05, mean = -1.3239e+04, std = 1.5609e+05\n[Raw] Param module.features.1.0.block.1.fc2.bias: norm = 1.9436e+04, min = -1.9364e+04, max = 7.6310e+02, mean = -6.4353e+02, std = 3.4290e+03\n[Raw] Param module.features.1.0.block.2.0.weight: norm = 6.2332e+06, min = -3.8135e+06, max = 1.2581e+06, mean = -2.5463e+04, std = 2.7456e+05\n[Raw] Param module.features.1.0.block.2.1.weight: norm = 3.0381e+06, min = -1.4526e+06, max = 8.8022e+05, mean = -1.5782e+05, std = 7.6731e+05\n[Raw] Param module.features.1.0.block.2.1.bias: norm = 4.2765e+00, min = -2.1120e+00, max = 2.1644e+00, mean = -3.3354e-01, std = 1.0491e+00\n[Raw] Param module.features.2.0.block.0.0.weight: norm = 1.7337e+06, min = -5.2738e+05, max = 8.3027e+05, mean = 5.2059e+02, std = 4.4248e+04\n[Raw] Param module.features.2.0.block.0.1.weight: norm = 1.1864e+07, min = -4.9630e+05, max = 1.1752e+07, mean = 1.4169e+05, std = 1.2088e+06\n[Raw] Param module.features.2.0.block.0.1.bias: norm = 1.4137e+06, min = -7.6613e+05, max = 5.0900e+05, mean = -1.0734e+04, std = 1.4464e+05\n[Raw] Param module.features.2.0.block.1.0.weight: norm = 2.6473e+06, min = -7.1266e+05, max = 1.3585e+06, mean = -7.8160e+03, std = 8.9776e+04\n[Raw] Param module.features.2.0.block.1.1.weight: norm = 9.4289e+05, min = -3.5500e+05, max = 2.7502e+05, mean = 6.5664e+03, std = 9.6513e+04\n[Raw] Param module.features.2.0.block.1.1.bias: norm = 2.3655e+06, min = -9.5672e+05, max = 5.4301e+05, mean = -8.1411e+03, std = 2.4256e+05\n[Raw] Param module.features.2.0.block.2.fc1.weight: norm = 2.7823e+06, min = -5.2806e+05, max = 8.3307e+05, mean = 3.9277e+04, std = 1.3662e+05\n[Raw] Param module.features.2.0.block.2.fc1.bias: norm = 2.8250e+04, min = -2.6066e+03, max = 2.8130e+04, mean = 6.3808e+03, std = 1.4551e+04\n[Raw] Param module.features.2.0.block.2.fc2.weight: norm = 1.9204e+06, min = -1.2918e+06, max = 8.8296e+05, mean = -3.7064e+03, std = 9.8060e+04\n[Raw] Param module.features.2.0.block.2.fc2.bias: norm = 1.8555e+05, min = -1.6704e+04, max = 1.8102e+05, mean = 1.6803e+03, std = 1.8962e+04\n[Raw] Param module.features.2.0.block.3.0.weight: norm = 1.1556e+06, min = -1.7288e+05, max = 3.6960e+05, mean = -1.5705e+01, std = 2.4080e+04\n[Raw] Param module.features.2.0.block.3.1.weight: norm = 6.0546e+05, min = -3.0141e+05, max = 2.8608e+05, mean = -5.0421e+03, std = 1.2614e+05\n[Raw] Param module.features.2.0.block.3.1.bias: norm = 3.8043e-01, min = -1.5525e-01, max = 1.3669e-01, mean = -5.4017e-03, std = 7.9133e-02\n[Raw] Param module.features.2.1.block.0.0.weight: norm = 4.1768e+05, min = -5.3156e+04, max = 1.2776e+05, mean = -7.4896e+00, std = 7.1060e+03\n[Raw] Param module.features.2.1.block.0.1.weight: norm = 1.1558e+07, min = -1.1480e+07, max = 7.5199e+05, mean = -8.1710e+04, std = 9.6302e+05\n[Raw] Param module.features.2.1.block.0.1.bias: norm = 2.3954e+05, min = -8.9738e+04, max = 1.1206e+05, mean = 1.0759e+03, std = 2.0002e+04\n[Raw] Param module.features.2.1.block.1.0.weight: norm = 9.2723e+05, min = -4.6718e+05, max = 2.3200e+05, mean = 1.0211e+03, std = 2.5746e+04\n[Raw] Param module.features.2.1.block.1.1.weight: norm = 5.4349e+05, min = -2.0615e+05, max = 2.2601e+05, mean = -5.6939e+02, std = 4.5446e+04\n[Raw] Param module.features.2.1.block.1.1.bias: norm = 1.9643e+05, min = -8.3143e+04, max = 4.4438e+04, mean = -1.7209e+03, std = 1.6335e+04\n[Raw] Param module.features.2.1.block.2.fc1.weight: norm = 1.4153e+05, min = -4.7266e+04, max = 1.7841e+04, mean = -8.1870e+02, std = 4.7477e+03\n[Raw] Param module.features.2.1.block.2.fc1.bias: norm = 1.1999e+03, min = -1.0988e+03, max = 4.1367e+02, mean = -1.5546e+02, std = 5.0889e+02\n[Raw] Param module.features.2.1.block.2.fc2.weight: norm = 2.1349e+05, min = -9.6958e+04, max = 1.6893e+05, mean = 1.8037e+02, std = 7.2649e+03\n[Raw] Param module.features.2.1.block.2.fc2.bias: norm = 3.5305e+01, min = -1.8051e+01, max = 2.9735e+01, mean = 1.3719e-01, std = 2.9491e+00\n[Raw] Param module.features.2.1.block.3.0.weight: norm = 8.2851e+05, min = -2.7302e+05, max = 3.1357e+05, mean = -2.4493e+01, std = 1.4095e+04\n[Raw] Param module.features.2.1.block.3.1.weight: norm = 4.6228e+05, min = -1.5170e+05, max = 1.6754e+05, mean = 2.1621e+04, std = 9.3828e+04\n[Raw] Param module.features.2.1.block.3.1.bias: norm = 1.1519e+04, min = -4.5982e+03, max = 4.1911e+03, mean = -9.7149e+02, std = 2.1873e+03\n[Raw] Param module.features.3.0.block.0.0.weight: norm = 9.5765e+05, min = -1.9214e+05, max = 2.7599e+05, mean = 2.8093e+02, std = 1.6290e+04\n[Raw] Param module.features.3.0.block.0.1.weight: norm = 2.0575e+07, min = -1.4208e+07, max = 1.3624e+07, mean = 1.2795e+04, std = 1.7205e+06\n[Raw] Param module.features.3.0.block.0.1.bias: norm = 1.2664e+06, min = -3.5512e+05, max = 8.2972e+05, mean = 8.3339e+03, std = 1.0557e+05\n[Raw] Param module.features.3.0.block.1.0.weight: norm = 1.1875e+06, min = -2.1013e+05, max = 2.8957e+05, mean = 2.2834e+02, std = 1.9793e+04\n[Raw] Param module.features.3.0.block.1.1.weight: norm = 1.0940e+06, min = -5.7495e+05, max = 1.7755e+05, mean = -1.3908e+04, std = 9.0414e+04\n[Raw] Param module.features.3.0.block.1.1.bias: norm = 2.0377e+06, min = -5.1555e+05, max = 8.9802e+05, mean = -6.8325e+03, std = 1.7027e+05\n[Raw] Param module.features.3.0.block.2.fc1.weight: norm = 2.2735e+06, min = -6.2862e+03, max = 1.0747e+06, mean = 2.0225e+04, std = 7.4699e+04\n[Raw] Param module.features.3.0.block.2.fc1.bias: norm = 2.5966e+04, min = 0.0000e+00, max = 2.5964e+04, mean = 4.3848e+03, std = 1.0572e+04\n[Raw] Param module.features.3.0.block.2.fc2.weight: norm = 2.2281e+05, min = -4.7585e+04, max = 2.1730e+05, mean = 2.0310e+02, std = 7.5818e+03\n[Raw] Param module.features.3.0.block.2.fc2.bias: norm = 2.5171e+05, min = -1.7088e+05, max = 9.8451e+04, mean = -2.7193e+02, std = 2.1047e+04\n[Raw] Param module.features.3.0.block.3.0.weight: norm = 7.7306e+05, min = -1.3912e+05, max = 1.0361e+05, mean = -2.2184e+02, std = 1.0184e+04\n[Raw] Param module.features.3.0.block.3.1.weight: norm = 4.9307e+05, min = -1.9587e+05, max = 1.5734e+05, mean = -8.7164e+03, std = 7.8460e+04\n[Raw] Param module.features.3.0.block.3.1.bias: norm = 2.1260e-01, min = -8.3945e-02, max = 6.3509e-02, mean = -4.5573e-03, std = 3.3729e-02\n[Raw] Param module.features.3.1.block.0.0.weight: norm = 2.0652e+05, min = -5.9884e+04, max = 7.5985e+04, mean = 1.9029e+01, std = 2.1079e+03\n[Raw] Param module.features.3.1.block.0.1.weight: norm = 1.7996e+06, min = -1.3872e+06, max = 6.4365e+05, mean = -5.6234e+03, std = 1.1627e+05\n[Raw] Param module.features.3.1.block.0.1.bias: norm = 3.5218e+05, min = -1.3838e+05, max = 1.4335e+05, mean = 1.7057e+03, std = 2.2716e+04\n[Raw] Param module.features.3.1.block.1.0.weight: norm = 2.5943e+05, min = -3.9733e+04, max = 6.0973e+04, mean = 1.8766e+02, std = 3.3443e+03\n[Raw] Param module.features.3.1.block.1.1.weight: norm = 2.1017e+05, min = -4.4913e+04, max = 1.1283e+05, mean = 6.6185e+02, std = 1.3578e+04\n[Raw] Param module.features.3.1.block.1.1.bias: norm = 4.1949e+05, min = -1.7728e+05, max = 1.2050e+05, mean = -1.6891e+03, std = 2.7082e+04\n[Raw] Param module.features.3.1.block.2.fc1.weight: norm = 3.1054e+05, min = -8.3331e+04, max = 6.0798e+04, mean = -3.0952e+02, std = 6.3327e+03\n[Raw] Param module.features.3.1.block.2.fc1.bias: norm = 1.9219e+03, min = -1.4700e+03, max = 1.0726e+03, mean = -5.5228e+01, std = 6.3799e+02\n[Raw] Param module.features.3.1.block.2.fc2.weight: norm = 3.4528e+05, min = -1.5381e+05, max = 1.3081e+05, mean = 8.8889e+01, std = 7.0489e+03\n[Raw] Param module.features.3.1.block.2.fc2.bias: norm = 6.7385e+01, min = -4.4964e+01, max = 3.9926e+01, mean = 8.5142e-02, std = 4.3580e+00\n[Raw] Param module.features.3.1.block.3.0.weight: norm = 2.7695e+05, min = -6.1758e+04, max = 3.8177e+04, mean = -6.4072e+01, std = 2.8261e+03\n[Raw] Param module.features.3.1.block.3.1.weight: norm = 4.8834e+05, min = -2.3481e+05, max = 1.0127e+05, mean = -1.5949e+04, std = 7.6510e+04\n[Raw] Param module.features.3.1.block.3.1.bias: norm = 6.3549e+05, min = -2.3485e+05, max = 2.2746e+05, mean = -1.3502e+04, std = 1.0084e+05\n[Raw] Param module.features.4.0.block.0.0.weight: norm = 8.3725e+05, min = -2.0316e+05, max = 1.4110e+05, mean = -2.6445e+01, std = 8.5456e+03\n[Raw] Param module.features.4.0.block.0.1.weight: norm = 5.9076e+06, min = -5.1483e+06, max = 2.3685e+06, mean = -1.2442e+04, std = 3.8193e+05\n[Raw] Param module.features.4.0.block.0.1.bias: norm = 2.4992e+06, min = -5.2700e+05, max = 2.2228e+06, mean = 1.0253e+04, std = 1.6133e+05\n[Raw] Param module.features.4.0.block.1.0.weight: norm = 1.0855e+06, min = -1.9643e+05, max = 2.4727e+05, mean = -3.1696e+02, std = 2.3359e+04\n[Raw] Param module.features.4.0.block.1.1.weight: norm = 1.1784e+06, min = -5.0395e+05, max = 3.7745e+05, mean = -4.2320e+00, std = 7.6224e+04\n[Raw] Param module.features.4.0.block.1.1.bias: norm = 4.2666e+06, min = -8.9192e+05, max = 1.1835e+06, mean = -1.4301e+04, std = 2.7561e+05\n[Raw] Param module.features.4.0.block.2.fc1.weight: norm = 1.7324e+06, min = -3.1079e+05, max = 1.4262e+05, mean = -4.6896e+03, std = 3.5057e+04\n[Raw] Param module.features.4.0.block.2.fc1.bias: norm = 1.8011e+04, min = -1.1886e+04, max = 6.2895e+03, mean = -1.2063e+03, std = 5.8676e+03\n[Raw] Param module.features.4.0.block.2.fc2.weight: norm = 1.3856e+06, min = -8.7314e+05, max = 9.9275e+05, mean = 6.1270e+01, std = 2.8289e+04\n[Raw] Param module.features.4.0.block.2.fc2.bias: norm = 2.9762e+02, min = -1.9723e+02, max = 2.2272e+02, mean = 6.2837e-02, std = 1.9251e+01\n[Raw] Param module.features.4.0.block.3.0.weight: norm = 1.2343e+06, min = -1.8364e+05, max = 3.3001e+05, mean = 7.0315e+01, std = 8.9076e+03\n[Raw] Param module.features.4.0.block.3.1.weight: norm = 3.9489e+05, min = -1.2035e+05, max = 1.0246e+05, mean = -9.5941e+02, std = 4.4418e+04\n[Raw] Param module.features.4.0.block.3.1.bias: norm = 1.4782e-01, min = -4.8516e-02, max = 6.3839e-02, mean = 2.2276e-04, std = 1.6630e-02\n[Raw] Param module.features.4.1.block.0.0.weight: norm = 4.9287e+05, min = -1.1327e+05, max = 1.5267e+05, mean = -5.3064e+00, std = 2.5152e+03\n[Raw] Param module.features.4.1.block.0.1.weight: norm = 1.1023e+06, min = -9.0911e+05, max = 3.5904e+05, mean = -9.9328e+02, std = 5.0357e+04\n[Raw] Param module.features.4.1.block.0.1.bias: norm = 1.4436e+06, min = -1.1635e+05, max = 1.2010e+06, mean = 6.2681e+03, std = 6.5663e+04\n[Raw] Param module.features.4.1.block.1.0.weight: norm = 5.0863e+05, min = -9.0199e+04, max = 6.3745e+04, mean = -4.9438e+01, std = 7.7394e+03\n[Raw] Param module.features.4.1.block.1.1.weight: norm = 3.7076e+05, min = -1.4349e+05, max = 9.0954e+04, mean = -1.8401e+02, std = 1.6940e+04\n[Raw] Param module.features.4.1.block.1.1.bias: norm = 9.2349e+05, min = -1.5612e+05, max = 1.6906e+05, mean = -3.7496e+02, std = 4.2194e+04\n[Raw] Param module.features.4.1.block.2.fc1.weight: norm = 7.1880e+05, min = -1.0299e+05, max = 8.1661e+04, mean = 1.2287e+02, std = 7.3356e+03\n[Raw] Param module.features.4.1.block.2.fc1.bias: norm = 2.3418e+03, min = -1.0701e+03, max = 8.4746e+02, mean = 1.6192e+01, std = 5.3698e+02\n[Raw] Param module.features.4.1.block.2.fc2.weight: norm = 8.4547e+05, min = -3.7895e+05, max = 9.9175e+03, mean = -2.5527e+02, std = 8.6257e+03\n[Raw] Param module.features.4.1.block.2.fc2.bias: norm = 4.5525e+01, min = -4.5516e+01, max = 8.9672e-01, mean = -9.3500e-02, std = 2.0780e+00\n[Raw] Param module.features.4.1.block.3.0.weight: norm = 2.2060e+04, min = -3.6716e+03, max = 3.1437e+03, mean = 5.3383e-01, std = 1.1258e+02\n[Raw] Param module.features.4.1.block.3.1.weight: norm = 2.7801e+04, min = -6.7529e+03, max = 9.3722e+03, mean = -2.6444e+02, std = 3.1165e+03\n[Raw] Param module.features.4.1.block.3.1.bias: norm = 4.1804e+03, min = -9.2170e+02, max = 1.2301e+03, mean = -8.0872e-01, std = 4.7034e+02\n[Raw] Param module.features.4.2.block.0.0.weight: norm = 1.4026e+04, min = -1.5300e+03, max = 1.5627e+03, mean = -1.3003e-01, std = 7.1578e+01\n[Raw] Param module.features.4.2.block.0.1.weight: norm = 3.6085e+04, min = -1.3564e+04, max = 2.0694e+04, mean = 7.0145e+01, std = 1.6473e+03\n[Raw] Param module.features.4.2.block.0.1.bias: norm = 2.3264e+04, min = -1.3146e+04, max = 1.1593e+04, mean = -3.3430e+01, std = 1.0624e+03\n[Raw] Param module.features.4.2.block.1.0.weight: norm = 2.4826e+04, min = -2.7386e+03, max = 5.8087e+03, mean = 2.6901e+01, std = 3.7680e+02\n[Raw] Param module.features.4.2.block.1.1.weight: norm = 1.8284e+04, min = -6.6084e+03, max = 3.9422e+03, mean = -2.2428e+01, std = 8.3510e+02\n[Raw] Param module.features.4.2.block.1.1.bias: norm = 2.1144e+04, min = -1.3266e+04, max = 5.4826e+03, mean = -2.1277e+01, std = 9.6586e+02\n[Raw] Param module.features.4.2.block.2.fc1.weight: norm = 4.0230e+03, min = -4.1882e+02, max = 4.6202e+02, mean = -2.3187e+00, std = 4.0996e+01\n[Raw] Param module.features.4.2.block.2.fc1.bias: norm = 1.3749e+01, min = -7.1083e+00, max = 7.8405e+00, mean = -3.1661e-01, std = 3.1374e+00\n[Raw] Param module.features.4.2.block.2.fc2.weight: norm = 8.5675e+03, min = -6.9224e+02, max = 5.4591e+03, mean = 2.7204e+00, std = 8.7404e+01\n[Raw] Param module.features.4.2.block.2.fc2.bias: norm = 2.7545e-01, min = -2.6157e-02, max = 2.1545e-01, mean = 8.4161e-04, std = 1.2557e-02\n[Raw] Param module.features.4.2.block.3.0.weight: norm = 2.6100e+04, min = -4.9280e+03, max = 7.5212e+03, mean = 1.2816e+00, std = 1.3318e+02\n[Raw] Param module.features.4.2.block.3.1.weight: norm = 2.8072e+04, min = -9.3999e+03, max = 7.7548e+03, mean = -4.6492e+02, std = 3.1235e+03\n[Raw] Param module.features.4.2.block.3.1.bias: norm = 9.2301e+03, min = -2.5528e+03, max = 3.4744e+03, mean = 1.8373e+02, std = 1.0219e+03\n[Raw] Param module.features.5.0.block.0.0.weight: norm = 4.6001e+04, min = -5.9316e+03, max = 4.1464e+03, mean = -3.6313e-01, std = 2.3475e+02\n[Raw] Param module.features.5.0.block.0.1.weight: norm = 2.2584e+06, min = -2.2239e+06, max = 2.7604e+05, mean = -3.8277e+03, std = 1.0312e+05\n[Raw] Param module.features.5.0.block.0.1.bias: norm = 1.7252e+05, min = -1.0275e+05, max = 5.4647e+04, mean = -5.3692e+02, std = 7.8643e+03\n[Raw] Param module.features.5.0.block.1.0.weight: norm = 7.6344e+04, min = -5.4444e+03, max = 8.3443e+03, mean = 2.1471e+01, std = 6.9662e+02\n[Raw] Param module.features.5.0.block.1.1.weight: norm = 1.0048e+05, min = -2.5409e+04, max = 2.1655e+04, mean = 4.7292e+01, std = 4.5906e+03\n[Raw] Param module.features.5.0.block.1.1.bias: norm = 2.9869e+05, min = -4.6463e+04, max = 5.2971e+04, mean = -3.0040e+02, std = 1.3644e+04\n[Raw] Param module.features.5.0.block.2.fc1.weight: norm = 1.3845e+05, min = -2.8377e+04, max = 1.6201e+04, mean = -7.9244e+01, std = 1.4109e+03\n[Raw] Param module.features.5.0.block.2.fc1.bias: norm = 8.1020e+02, min = -5.9635e+02, max = 3.4096e+02, mean = -1.8659e+01, std = 1.8488e+02\n[Raw] Param module.features.5.0.block.2.fc2.weight: norm = 3.4345e+05, min = -2.3845e+05, max = 2.9338e+04, mean = -8.5869e+01, std = 3.5045e+03\n[Raw] Param module.features.5.0.block.2.fc2.bias: norm = 3.6052e+01, min = -3.4802e+01, max = 4.1550e+00, mean = -8.7237e-02, std = 1.6449e+00\n[Raw] Param module.features.5.0.block.3.0.weight: norm = 1.3792e+04, min = -1.2733e+03, max = 1.5743e+03, mean = 7.6968e-01, std = 5.9479e+01\n[Raw] Param module.features.5.0.block.3.1.weight: norm = 1.2198e+04, min = -3.5085e+03, max = 3.8777e+03, mean = 2.4863e+01, std = 1.1575e+03\n[Raw] Param module.features.5.0.block.3.1.bias: norm = 2.5706e-03, min = -5.0117e-04, max = 5.3834e-04, mean = -7.1482e-06, std = 2.4389e-04\n[Raw] Param module.features.5.1.block.0.0.weight: norm = 8.8408e+03, min = -1.3570e+03, max = 2.1317e+03, mean = -6.2982e-02, std = 3.2226e+01\n[Raw] Param module.features.5.1.block.0.1.weight: norm = 4.8666e+04, min = -2.5854e+04, max = 2.1759e+04, mean = -1.5692e+01, std = 1.8787e+03\n[Raw] Param module.features.5.1.block.0.1.bias: norm = 2.4686e+04, min = -4.7291e+03, max = 1.3941e+04, mean = 6.4411e+01, std = 9.5083e+02\n[Raw] Param module.features.5.1.block.1.0.weight: norm = 1.4223e+04, min = -1.7011e+03, max = 1.3257e+03, mean = 1.7634e+00, std = 1.0972e+02\n[Raw] Param module.features.5.1.block.1.1.weight: norm = 1.1443e+04, min = -2.2664e+03, max = 3.0313e+03, mean = 6.5927e-01, std = 4.4176e+02\n[Raw] Param module.features.5.1.block.1.1.bias: norm = 3.8205e+04, min = -6.0419e+03, max = 6.7185e+03, mean = 2.6407e+01, std = 1.4746e+03\n[Raw] Param module.features.5.1.block.2.fc1.weight: norm = 3.1717e+04, min = -3.8517e+03, max = 3.4022e+03, mean = -1.7037e+01, std = 2.3060e+02\n[Raw] Param module.features.5.1.block.2.fc1.bias: norm = 8.4122e+01, min = -4.5282e+01, max = 3.9911e+01, mean = -2.0993e+00, std = 1.6048e+01\n[Raw] Param module.features.5.1.block.2.fc2.weight: norm = 4.0164e+04, min = -3.2846e+03, max = 1.9736e+04, mean = 6.9648e+00, std = 2.9273e+02\n[Raw] Param module.features.5.1.block.2.fc2.bias: norm = 1.1610e+00, min = -2.0468e-01, max = 1.0570e+00, mean = 1.9598e-03, std = 4.4778e-02\n[Raw] Param module.features.5.1.block.3.0.weight: norm = 3.6209e+03, min = -3.2740e+02, max = 4.9689e+02, mean = -8.7906e-02, std = 1.3198e+01\n[Raw] Param module.features.5.1.block.3.1.weight: norm = 4.9968e+03, min = -1.5057e+03, max = 1.1788e+03, mean = 1.5687e+01, std = 4.7402e+02\n[Raw] Param module.features.5.1.block.3.1.bias: norm = 5.3259e+02, min = -1.5199e+02, max = 1.2980e+02, mean = -1.7044e+00, std = 5.0522e+01\n[Raw] Param module.features.5.2.block.0.0.weight: norm = 3.0397e+03, min = -3.3689e+02, max = 3.1128e+02, mean = 9.4610e-02, std = 1.1080e+01\n[Raw] Param module.features.5.2.block.0.1.weight: norm = 1.3328e+04, min = -6.7139e+03, max = 5.9279e+03, mean = -1.3918e+01, std = 5.1434e+02\n[Raw] Param module.features.5.2.block.0.1.bias: norm = 5.2219e+03, min = -2.1793e+03, max = 2.7846e+03, mean = 9.2830e+00, std = 2.0138e+02\n[Raw] Param module.features.5.2.block.1.0.weight: norm = 3.5281e+03, min = -4.8981e+02, max = 5.8586e+02, mean = 3.3495e-02, std = 2.7220e+01\n[Raw] Param module.features.5.2.block.1.1.weight: norm = 3.6656e+03, min = -5.8170e+02, max = 9.7029e+02, mean = 8.1989e+00, std = 1.4127e+02\n[Raw] Param module.features.5.2.block.1.1.bias: norm = 6.1036e+03, min = -9.5649e+02, max = 1.4113e+03, mean = 2.5938e+00, std = 2.3561e+02\n[Raw] Param module.features.5.2.block.2.fc1.weight: norm = 5.2721e+03, min = -7.4079e+02, max = 4.4626e+02, mean = -4.1371e-01, std = 3.8433e+01\n[Raw] Param module.features.5.2.block.2.fc1.bias: norm = 1.4244e+01, min = -8.5811e+00, max = 5.2177e+00, mean = -6.1403e-02, std = 2.7406e+00\n[Raw] Param module.features.5.2.block.2.fc2.weight: norm = 4.9786e+03, min = -2.3433e+03, max = 1.7234e+02, mean = -1.2745e+00, std = 3.6273e+01\n[Raw] Param module.features.5.2.block.2.fc2.bias: norm = 1.3832e-01, min = -1.2446e-01, max = 9.3658e-03, mean = -2.6566e-04, std = 5.3332e-03\n[Raw] Param module.features.5.2.block.3.0.weight: norm = 3.6990e+03, min = -3.5535e+02, max = 4.3477e+02, mean = 5.2571e-02, std = 1.3483e+01\n[Raw] Param module.features.5.2.block.3.1.weight: norm = 5.2505e+03, min = -1.2331e+03, max = 1.4521e+03, mean = -4.4003e+00, std = 4.9834e+02\n[Raw] Param module.features.5.2.block.3.1.bias: norm = 4.0430e+02, min = -8.2286e+01, max = 9.3219e+01, mean = 6.1174e+00, std = 3.7879e+01\n[Raw] Param module.features.6.0.block.0.0.weight: norm = 7.9156e+03, min = -1.0230e+03, max = 1.2025e+03, mean = -1.5056e-01, std = 2.8853e+01\n[Raw] Param module.features.6.0.block.0.1.weight: norm = 8.3854e+04, min = -3.5380e+04, max = 6.0891e+04, mean = 3.4850e+01, std = 3.2370e+03\n[Raw] Param module.features.6.0.block.0.1.bias: norm = 1.3974e+04, min = -6.0743e+03, max = 3.4575e+03, mean = -3.2475e+01, std = 5.3850e+02\n[Raw] Param module.features.6.0.block.1.0.weight: norm = 9.3119e+03, min = -8.3964e+02, max = 8.2207e+02, mean = 2.1316e+00, std = 7.1813e+01\n[Raw] Param module.features.6.0.block.1.1.weight: norm = 1.1005e+04, min = -4.3280e+03, max = 2.6509e+03, mean = 3.9975e+00, std = 4.2481e+02\n[Raw] Param module.features.6.0.block.1.1.bias: norm = 1.0116e+04, min = -1.8022e+03, max = 1.5242e+03, mean = 1.7947e+01, std = 3.9011e+02\n[Raw] Param module.features.6.0.block.2.fc1.weight: norm = 6.6244e+03, min = -6.1096e+02, max = 6.3313e+02, mean = -2.7462e+00, std = 4.8216e+01\n[Raw] Param module.features.6.0.block.2.fc1.bias: norm = 1.7137e+01, min = -6.6656e+00, max = 7.0042e+00, mean = -2.5463e-01, std = 3.2879e+00\n[Raw] Param module.features.6.0.block.2.fc2.weight: norm = 8.1779e+03, min = -4.2224e+02, max = 4.2557e+03, mean = 1.3478e+00, std = 5.9605e+01\n[Raw] Param module.features.6.0.block.2.fc2.bias: norm = 1.5772e-01, min = -1.7828e-02, max = 1.5616e-01, mean = 2.2171e-04, std = 6.0846e-03\n[Raw] Param module.features.6.0.block.3.0.weight: norm = 1.2389e+03, min = -1.0968e+02, max = 1.3654e+02, mean = 4.3082e-02, std = 3.4488e+00\n[Raw] Param module.features.6.0.block.3.1.weight: norm = 8.9293e+02, min = -2.0114e+02, max = 2.7342e+02, mean = 4.5697e+00, std = 6.4448e+01\n[Raw] Param module.features.6.0.block.3.1.bias: norm = 3.3159e-04, min = -6.7853e-05, max = 9.0436e-05, mean = -1.4899e-06, std = 2.3946e-05\n[Raw] Param module.features.6.1.block.0.0.weight: norm = 8.1898e+02, min = -1.6216e+02, max = 1.0318e+02, mean = -1.4584e-03, std = 1.7414e+00\n[Raw] Param module.features.6.1.block.0.1.weight: norm = 4.1847e+03, min = -2.8279e+03, max = 1.4142e+03, mean = -4.1425e+00, std = 1.2328e+02\n[Raw] Param module.features.6.1.block.0.1.bias: norm = 1.7229e+03, min = -9.8405e+02, max = 4.8520e+02, mean = 1.3860e-01, std = 5.0782e+01\n[Raw] Param module.features.6.1.block.1.0.weight: norm = 7.3016e+02, min = -6.2532e+01, max = 7.6139e+01, mean = -1.2339e-01, std = 4.3008e+00\n[Raw] Param module.features.6.1.block.1.1.weight: norm = 8.4981e+02, min = -2.5482e+02, max = 1.9182e+02, mean = -1.0554e+00, std = 2.5026e+01\n[Raw] Param module.features.6.1.block.1.1.bias: norm = 2.6310e+03, min = -3.1868e+02, max = 3.6083e+02, mean = 1.0167e-01, std = 7.7550e+01\n[Raw] Param module.features.6.1.block.2.fc1.weight: norm = 2.4149e+03, min = -8.2978e+01, max = 2.0253e+02, mean = 1.5190e+00, std = 1.0157e+01\n[Raw] Param module.features.6.1.block.2.fc1.bias: norm = 4.0185e+00, min = -1.0275e+00, max = 2.5086e+00, mean = 1.4666e-01, std = 5.6711e-01\n[Raw] Param module.features.6.1.block.2.fc2.weight: norm = 3.0747e+03, min = -1.5056e+03, max = 7.8210e+01, mean = -2.0895e-01, std = 1.3074e+01\n[Raw] Param module.features.6.1.block.2.fc2.bias: norm = 3.1137e-02, min = -3.1048e-02, max = 1.5828e-03, mean = -2.5796e-05, std = 9.1742e-04\n[Raw] Param module.features.6.1.block.3.0.weight: norm = 5.5599e+01, min = -5.2371e+00, max = 6.9830e+00, mean = -1.3222e-03, std = 1.1821e-01\n[Raw] Param module.features.6.1.block.3.1.weight: norm = 6.9286e+01, min = -1.6392e+01, max = 1.6323e+01, mean = -3.2304e-01, std = 5.0029e+00\n[Raw] Param module.features.6.1.block.3.1.bias: norm = 2.1962e+01, min = -4.6857e+00, max = 3.3912e+00, mean = -1.6662e-01, std = 1.5803e+00\n[Raw] Param module.features.6.2.block.0.0.weight: norm = 6.0077e+01, min = -1.1562e+01, max = 1.6264e+01, mean = 2.2343e-04, std = 1.2774e-01\n[Raw] Param module.features.6.2.block.0.1.weight: norm = 3.8063e+02, min = -4.4659e+01, max = 3.0491e+02, mean = 5.5386e-01, std = 1.1206e+01\n[Raw] Param module.features.6.2.block.0.1.bias: norm = 1.1031e+02, min = -6.0312e+01, max = 6.0851e+01, mean = 7.1764e-02, std = 3.2508e+00\n[Raw] Param module.features.6.2.block.1.0.weight: norm = 3.3866e+01, min = -3.0935e+00, max = 6.0888e+00, mean = -2.3378e-03, std = 1.9955e-01\n[Raw] Param module.features.6.2.block.1.1.weight: norm = 3.0354e+01, min = -6.8558e+00, max = 4.9688e+00, mean = 7.3941e-03, std = 8.9468e-01\n[Raw] Param module.features.6.2.block.1.1.bias: norm = 4.3757e+01, min = -8.7926e+00, max = 6.1869e+00, mean = -3.6482e-02, std = 1.2893e+00\n[Raw] Param module.features.6.2.block.2.fc1.weight: norm = 3.5323e+01, min = -1.8194e+00, max = 1.4904e+00, mean = 4.8404e-03, std = 1.5014e-01\n[Raw] Param module.features.6.2.block.2.fc1.bias: norm = 5.5830e-02, min = -2.5389e-02, max = 2.0573e-02, mean = 4.1337e-04, std = 8.1329e-03\n[Raw] Param module.features.6.2.block.2.fc2.weight: norm = 3.6957e+01, min = -7.6827e+00, max = 1.2870e+01, mean = 2.1945e-03, std = 1.5715e-01\n[Raw] Param module.features.6.2.block.2.fc2.bias: norm = 4.9300e-04, min = -2.2365e-04, max = 3.1340e-04, mean = 3.4824e-07, std = 1.4527e-05\n[Raw] Param module.features.6.2.block.3.0.weight: norm = 3.1089e+01, min = -2.3637e+00, max = 3.0856e+00, mean = 8.4711e-04, std = 6.6099e-02\n[Raw] Param module.features.6.2.block.3.1.weight: norm = 4.4060e+01, min = -1.2839e+01, max = 1.1617e+01, mean = 1.5820e-02, std = 3.1880e+00\n[Raw] Param module.features.6.2.block.3.1.bias: norm = 2.5607e+01, min = -6.5823e+00, max = 4.9159e+00, mean = 2.5398e-01, std = 1.8353e+00\n[Raw] Param module.features.6.3.block.0.0.weight: norm = 3.0172e+01, min = -3.2300e+00, max = 5.4414e+00, mean = 2.8522e-04, std = 6.4154e-02\n[Raw] Param module.features.6.3.block.0.1.weight: norm = 3.4750e+02, min = -2.6151e+02, max = 9.3160e+01, mean = -3.1743e-01, std = 1.0238e+01\n[Raw] Param module.features.6.3.block.0.1.bias: norm = 5.4143e+01, min = -2.1125e+01, max = 2.5758e+01, mean = 3.7454e-02, std = 1.5955e+00\n[Raw] Param module.features.6.3.block.1.0.weight: norm = 2.9283e+01, min = -3.4028e+00, max = 3.0609e+00, mean = 1.5578e-03, std = 1.7255e-01\n[Raw] Param module.features.6.3.block.1.1.weight: norm = 2.6358e+01, min = -3.6802e+00, max = 4.2766e+00, mean = 3.2509e-02, std = 7.7624e-01\n[Raw] Param module.features.6.3.block.1.1.bias: norm = 5.8254e+01, min = -9.2097e+00, max = 7.7868e+00, mean = 1.0952e-03, std = 1.7171e+00\n[Raw] Param module.features.6.3.block.2.fc1.weight: norm = 5.4775e+01, min = -1.9990e+00, max = 2.7632e+00, mean = 1.9788e-02, std = 2.3210e-01\n[Raw] Param module.features.6.3.block.2.fc1.bias: norm = 7.9339e-02, min = -2.3057e-02, max = 3.2292e-02, mean = 1.6253e-03, std = 1.1456e-02\n[Raw] Param module.features.6.3.block.2.fc2.weight: norm = 5.3179e+01, min = -1.8431e+01, max = 1.3111e+01, mean = -3.2624e-03, std = 2.2613e-01\n[Raw] Param module.features.6.3.block.2.fc2.bias: norm = 5.4136e-04, min = -3.9377e-04, max = 2.7448e-04, mean = -4.3178e-07, std = 1.5951e-05\n[Raw] Param module.features.6.3.block.3.0.weight: norm = 2.4823e+01, min = -3.4462e+00, max = 3.5561e+00, mean = 4.0311e-05, std = 5.2780e-02\n[Raw] Param module.features.6.3.block.3.1.weight: norm = 2.8793e+01, min = -7.7025e+00, max = 6.6511e+00, mean = -3.0323e-01, std = 2.0611e+00\n[Raw] Param module.features.6.3.block.3.1.bias: norm = 2.4944e+01, min = -4.5829e+00, max = 4.4785e+00, mean = 1.4426e-03, std = 1.8049e+00\n[Raw] Param module.features.7.0.block.0.0.weight: norm = 5.8933e+01, min = -3.8071e+00, max = 5.1805e+00, mean = 1.5296e-04, std = 1.2531e-01\n[Raw] Param module.features.7.0.block.0.1.weight: norm = 4.8748e+02, min = -1.9811e+02, max = 2.9919e+02, mean = 1.7944e-01, std = 1.4368e+01\n[Raw] Param module.features.7.0.block.0.1.bias: norm = 2.1691e+02, min = -9.0114e+01, max = 1.0992e+02, mean = 2.3682e-02, std = 6.3934e+00\n[Raw] Param module.features.7.0.block.1.0.weight: norm = 1.2512e+02, min = -3.6891e+01, max = 1.1123e+01, mean = -4.3521e-02, std = 1.2281e+00\n[Raw] Param module.features.7.0.block.1.1.weight: norm = 8.9062e+01, min = -2.2265e+01, max = 1.2568e+01, mean = -7.9674e-02, std = 2.6240e+00\n[Raw] Param module.features.7.0.block.1.1.bias: norm = 2.5841e+02, min = -3.0505e+01, max = 3.6176e+01, mean = 8.1037e-03, std = 7.6168e+00\n[Raw] Param module.features.7.0.block.2.fc1.weight: norm = 2.6121e+02, min = -1.4501e+01, max = 9.1086e+00, mean = -3.7494e-02, std = 1.1102e+00\n[Raw] Param module.features.7.0.block.2.fc1.bias: norm = 4.3023e-01, min = -1.6538e-01, max = 1.0079e-01, mean = -3.6009e-03, std = 6.2650e-02\n[Raw] Param module.features.7.0.block.2.fc2.weight: norm = 1.8936e+02, min = -1.6405e+01, max = 7.4676e+01, mean = 2.2158e-02, std = 8.0496e-01\n[Raw] Param module.features.7.0.block.2.fc2.bias: norm = 2.8495e-03, min = -5.3707e-04, max = 2.4333e-03, mean = 3.7573e-06, std = 8.3908e-05\n[Raw] Param module.features.7.0.block.3.0.weight: norm = 8.6225e+00, min = -6.7604e-01, max = 4.0804e-01, mean = -2.4999e-04, std = 1.4199e-02\n[Raw] Param module.features.7.0.block.3.1.weight: norm = 9.7111e+00, min = -1.6375e+00, max = 1.7269e+00, mean = 5.4608e-03, std = 5.4369e-01\n[Raw] Param module.features.7.0.block.3.1.bias: norm = 5.6565e-06, min = -8.9744e-07, max = 8.9396e-07, mean = -7.9490e-09, std = 3.1660e-07\n[Raw] Param module.features.8.0.weight: norm = 8.2753e+00, min = -4.5669e-01, max = 4.3892e-01, mean = 2.3676e-05, std = 1.2930e-02\n[Raw] Param module.features.8.1.weight: norm = 3.4497e+01, min = -4.4015e+00, max = 5.3920e+00, mean = 2.2338e-02, std = 9.6433e-01\n[Raw] Param module.features.8.1.bias: norm = 1.2193e+02, min = -1.6089e+01, max = 2.5999e+01, mean = 1.3325e-01, std = 3.4066e+00\n[Raw] Param module.classifier.1.weight: norm = 3.7947e+02, min = -2.9746e+01, max = 4.3140e+01, mean = -3.9736e-09, std = 6.1245e+00\n[Raw] Param module.classifier.1.bias: norm = 4.9635e-01, min = -2.8278e-01, max = 3.9280e-01, mean = 0.0000e+00, std = 3.5097e-01\nIteration 2: Total gradient norm before clipping = 175919750.7949\nIteration 2: Total gradient norm after clipping  = 0.0000\nIteration 2: Total Newton update norm = 0.0000\nIteration 2/2 update completed.\nExecution time: 455.970217 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Unlearn","metadata":{}},{"cell_type":"code","source":"save_model(unlearned_model, f'{model_to_unlearn_name}_model.pth')","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:09:53.152896Z","iopub.execute_input":"2025-04-03T17:09:53.153815Z","iopub.status.idle":"2025-04-03T17:09:53.226861Z","shell.execute_reply.started":"2025-04-03T17:09:53.153779Z","shell.execute_reply":"2025-04-03T17:09:53.225849Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\nclasses = test_dataset.classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:09:58.881854Z","iopub.execute_input":"2025-04-03T17:09:58.882229Z","iopub.status.idle":"2025-04-03T17:09:58.887486Z","shell.execute_reply.started":"2025-04-03T17:09:58.882195Z","shell.execute_reply":"2025-04-03T17:09:58.886266Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### Test and metrics","metadata":{}},{"cell_type":"code","source":"model, *_ = init_model_effnetb0()\nmodel = nn.DataParallel(model, device_ids=[0, 1])\nmodel_path = f\"{model_to_unlearn_name}_model.pth\"\ntest_model(model, model_to_unlearn_name, model_path, test_loader)","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:10:01.046203Z","iopub.execute_input":"2025-04-03T17:10:01.047216Z","iopub.status.idle":"2025-04-03T17:10:14.131369Z","shell.execute_reply.started":"2025-04-03T17:10:01.047163Z","shell.execute_reply":"2025-04-03T17:10:14.130487Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Init model...\nDone initializing model.\nModel ID: 132829041425760, Optimizer ID: 132825597979872, Criterion ID: 132825597976800\nLoading and testing model: fisher_EffNetB0_AFHQ\n","output_type":"stream"},{"name":"stderr","text":"Evaluating model: fisher_EffNetB0_AFHQ_model.pth:   0%|          | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEvaluating model: fisher_EffNetB0_AFHQ_model.pth: 100%|██████████| 6/6 [00:12<00:00,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Predictions and labels saved to fisher_EffNetB0_AFHQ_predictions.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"predictions_path = f'{model_to_unlearn_name}_predictions.json'\n# classes = ['cat', 'dog', 'wildlife']\nshow_metrics(predictions_path, classes, model_to_unlearn_name)","metadata":{"execution":{"iopub.status.busy":"2025-04-03T17:10:16.371990Z","iopub.execute_input":"2025-04-03T17:10:16.372845Z","iopub.status.idle":"2025-04-03T17:10:16.653050Z","shell.execute_reply.started":"2025-04-03T17:10:16.372806Z","shell.execute_reply":"2025-04-03T17:10:16.652122Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Metrics for fisher_EffNetB0_AFHQ:\n  - Test Accuracy: 0.3333\n  - Precision: 0.1112\n  - Recall: 0.3333\n  - F1 Score: 0.1668\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}}],"execution_count":22}]}